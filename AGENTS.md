---
Version: 2.0
Last Updated: 2025-12-17
Python: 3.10+
Gradio: 6.x
SAM3: Via submodule
---

# Developer Guidelines & Agent Memory

> **âš ï¸ AUTO-GENERATED FILE**: This file is generated by `scripts/update_agents_md.py`.
> Manual edits to the code skeletons will be overwritten.
> To update the guidelines, edit the static sections in the script.

**âš ï¸ CRITICAL**: Read this before starting any task.

ðŸ”´ CRITICAL | ðŸŸ¡ WARNING | ðŸŸ¢ BEST PRACTICE


## 1. Quick Start Guide

### 5-Minute Setup
1. **Clone & Submodules**: `git submodule update --init --recursive`
2. **Environment**: `python3 -m venv venv && source venv/bin/activate`
3. **Dependencies**: `pip install -r requirements.txt` (Installs SAM3 via submodule)
4. **Run App**: `python app.py`

### Essential Commands
- **Unit Tests**: `python -m pytest tests/` (Fast, uses mocks)
- **Smoke Tests**: `python -m pytest tests/test_smoke.py` (No mocks, catches import errors)
- **Signature Tests**: `python -m pytest tests/test_signatures.py` (Validates function interfaces)
- **Integration Tests**: `python -m pytest tests/test_integration.py -m integration` (GPU required)
- **E2E Tests**: `python -m pytest tests/e2e/` (Requires App running + Playwright)

### Test Strategy
| Test Type | File | Purpose | GPU? |
|-----------|------|---------|------|
| Unit | `test_*.py` | Logic with mocks | No |
| Smoke | `test_smoke.py` | Import validation | No |
| Signature | `test_signatures.py` | Function interfaces | No |
| Integration | `test_integration.py` | Real dependencies | Yes |
| E2E | `tests/e2e/` | Full app flow | Yes |

### Directory Structure
- `app.py`: Entry point.
- `core/`: Business logic (pipelines, config, db).
- `ui/`: Gradio interface components.
- `tests/`: Unit, smoke, signature, integration, and E2E tests.
- `SAM3_repo/`: **Read-only** submodule.


## 2. Critical Rules

### ðŸ”´ CRITICAL (Must Follow)
- **NEVER** edit files in `SAM3_repo`. Treat as an external library.
- **NEVER** import from `ui/` in `core/` modules. Use callbacks or `core/shared.py` for shared functionality.
- **ALWAYS** match Gradio event handler return values count to the `outputs` list. Mismatches crash the app silently.
- **NEVER** use `@lru_cache` on functions taking the `Config` object (it's unhashable). Use `model_registry.get_or_load`.
- **ALWAYS** use `pathlib.Path`, never `os.path` or `os.access`.
- **ALWAYS** mock external dependencies (SAM3, Torch) in unit tests.
- **ALWAYS** use `tests/conftest.py` fixtures for mock objects in tests.

### ðŸŸ¡ WARNING (Potential Bugs)
- **Check Masks**: Verify masks exist on disk before export/processing.
- **Thread Safety**: MediaPipe objects are not thread-safe. Use thread-local storage or one instance per thread.
- **Gradio State**: Do not store locks or file handles in `gr.State`.
- **Circular Imports**: If you need UI functions in core, add them to `core/shared.py`.

### ðŸŸ¢ BEST PRACTICE
- **Refactoring**: Move logic from `app.py` to `core/`.
- **Typing**: Use Pydantic models (`core/events.py`) instead of untyped dicts.
- **Testing**: Add fixtures to `tests/conftest.py` for reuse across test files.


## 3. Architecture Overview

### Data Flow
`UI (Gradio)` â†’ `Event Object (Pydantic)` â†’ `Pipeline (Core)` â†’ `Database/Files`

### Component Relationship
```
[app.py] (UI Assembly)
   â”‚
   â”œâ”€ [core/config.py] (Settings)
   â”œâ”€ [core/managers.py] (ModelRegistry, ThumbnailManager)
   â””â”€ [core/pipelines.py] (Logic)
         â”‚
         â”œâ”€ ExtractionPipeline (FFmpeg)
         â”œâ”€ AnalysisPipeline (SAM3, InsightFace)
         â””â”€ ExportPipeline (Filtering, Rendering)
```

### State Management
- **Session State**: `gr.State` stores mutable data (scene lists, paths).
- **Global State**: `ModelRegistry` (Singleton-like) manages heavy models.
- **Persistence**: `metadata.db` (SQLite) for frame data; `json` for configs.

## 4. Code Skeleton Reference

### `ðŸ“„ app.py`

```python
"""
Frame Extractor & Analyzer v2.0
"""

import sys
from pathlib import Path
import threading
from queue import Queue
import torch
import gc
from core.config import Config
from core.logger import AppLogger
from core.managers import ModelRegistry, ThumbnailManager
from ui.app_ui import AppUI

project_root = Path(__file__).parent
def cleanup_models(model_registry):
    """
    Clears the model registry and performs garbage collection.

    Args:
    model_registry: The ModelRegistry instance to clear.
    """
    ...

def main():
    """
    Main entry point for the application.

    Initializes configuration, logging, managers, and the Gradio UI.
    """
    ...

```

### `ðŸ“„ core/__init__.py`

```python

```

### `ðŸ“„ core/batch_manager.py`

```python
import threading
import uuid
import time
from typing import List, Optional, Callable, Dict
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor

class BatchStatus(Enum):
    PENDING = 'Pending'
    PROCESSING = 'Processing'
    COMPLETED = 'Completed'
    FAILED = 'Failed'
    CANCELLED = 'Cancelled'

@dataclass
class BatchItem:
    """
    Represents a single item in the batch processing queue.
    """
    ...

class BatchManager:
    """
    Manages a queue of batch processing tasks.
    """
    def __init__(self):
        """
        Initializes the BatchManager.
        """
        ...
    def add_paths(self, paths: List[str]):
        """
        Adds a list of file paths to the batch queue.
        """
        ...
    def get_queue_snapshot(self) -> List[BatchItem]:
        """
        Returns a thread-safe snapshot of the current queue.
        """
        ...
    def get_status_list(self) -> List[List]:
        """
        Returns a simplified list of status data for the UI.
        """
        ...
    def clear_completed(self):
        """
        Removes completed, failed, and cancelled items from the queue.
        """
        ...
    def clear_all(self):
        """
        Clears all items from the queue.
        """
        ...
    def update_progress(self, item_id: str, fraction: float, message: Optional[str]=None):
        """
        Updates the progress of a specific batch item.
        """
        ...
    def set_status(self, item_id: str, status: BatchStatus, message: Optional[str]=None):
        """
        Updates the status and message of a specific batch item.
        """
        ...
    def start_processing(self, processor_func: Callable, max_workers: int=1):
        """
        Starts processing the batch queue in a background thread.

        Args:
        processor_func: Function to process each item.
        max_workers: Number of concurrent worker threads.
        """
        ...
    def _run_scheduler(self, processor_func, max_workers):
        ...
    def stop_processing(self):
        """
        Signals the scheduler to stop processing.
        """
        ...

```

### `ðŸ“„ core/config.py`

```python
"""
Configuration Management for Frame Extractor & Analyzer
"""

import json
from pathlib import Path
from typing import Any, Dict, List, Optional
from pydantic import Field, model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict

def json_config_settings_source() -> Dict[str, Any]:
    """
    Loads settings from a JSON file for Pydantic settings.
    """
    ...

class Config(BaseSettings):
    """
    Manages the application's configuration settings.
    """
    model_config = SettingsConfigDict(env_file='.env', env_prefix='APP_', env_nested_delimiter='_', case_sensitive=False)
    def model_post_init(self, __context: Any) -> None:
        """
        Post-initialization hook to validate paths.
        """
        ...
    def _validate_paths(self):
        """
        Ensures critical directories exist and are writable.
        """
        ...
    @model_validator(mode='after')
    def _validate_config(self) -> 'Config':
        """
        Validates that at least one quality weight is non-zero.
        """
        ...
    @property
    def quality_weights(self) -> Dict[str, int]:
        """
        Returns a dictionary of quality metric weights.
        """
        ...

```

### `ðŸ“„ core/database.py`

```python
import sqlite3
import json
import threading
from pathlib import Path
from typing import List, Dict, Any

class Database:
    def __init__(self, db_path: Path, batch_size: int=50):
        """
        Initializes the Database manager.

        Args:
        db_path: Path to the SQLite database file.
        batch_size: Number of records to buffer before writing.
        """
        ...
    def connect(self):
        """
        Connects to the SQLite database.
        """
        ...
    def close(self):
        """
        Closes the database connection.
        """
        ...
    def create_tables(self):
        """
        Creates the necessary tables if they don't exist.
        """
        ...
    def clear_metadata(self):
        """
        Deletes all records from the metadata table.
        """
        ...
    def insert_metadata(self, metadata: Dict[str, Any]):
        """
        Inserts or replaces a metadata record.
        """
        ...
    def flush(self):
        """
        Manually flush the buffer.
        """
        ...
    def _flush_buffer(self):
        """
        Internal method to write buffered records to the database.
        """
        ...
    def load_all_metadata(self) -> List[Dict[str, Any]]:
        """
        Loads all metadata from the database.
        """
        ...
    def count_errors(self) -> int:
        """
        Counts the number of records with errors.
        """
        ...

```

### `ðŸ“„ core/error_handling.py`

```python
"""
Error Handling Infrastructure for Frame Extractor & Analyzer
"""

import functools
import time
import traceback
from enum import Enum
from typing import Any, Callable, Optional

class ErrorSeverity(Enum):
    LOW = 'low'
    MEDIUM = 'medium'
    HIGH = 'high'
    CRITICAL = 'critical'

class RecoveryStrategy(Enum):
    RETRY = 'retry'
    FALLBACK = 'fallback'
    SKIP = 'skip'
    ABORT = 'abort'

class ErrorHandler:
    def __init__(self, logger: 'AppLogger', max_attempts: int, backoff_seconds: list):
        """
        Initializes the ErrorHandler.

        Args:
        logger: Application logger.
        max_attempts: Default maximum retry attempts.
        backoff_seconds: List of backoff delays in seconds.
        """
        ...
    def with_retry(self, max_attempts: Optional[int]=None, backoff_seconds: Optional[list]=None, recoverable_exceptions: tuple=(Exception,)):
        """
        Decorator that retries the function call upon failure.

        Args:
        max_attempts: Maximum number of attempts.
        backoff_seconds: List of backoff times between retries.
        recoverable_exceptions: Tuple of exceptions to catch and retry.

        Returns:
        Decorated function.
        """
        ...
    def with_fallback(self, fallback_func: Callable):
        """
        Decorator that executes a fallback function if the primary function fails.

        Args:
        fallback_func: Function to call on failure.

        Returns:
        Decorated function.
        """
        ...

```

### `ðŸ“„ core/events.py`

```python
"""
Event Models for Frame Extractor & Analyzer

Pydantic models representing UI events and data contracts.
"""

from pathlib import Path
from typing import Any, Optional
from pydantic import BaseModel, ConfigDict, field_validator, model_validator

class UIEvent(BaseModel):
    """
    Base class for all UI-triggered events.
    """
    model_config = ConfigDict(validate_assignment=True, extra='ignore', str_strip_whitespace=True, arbitrary_types_allowed=True)

class ExtractionEvent(UIEvent):
    """
    Data model for frame extraction events.
    """
    ...

class PreAnalysisEvent(UIEvent):
    """
    Data model for pre-analysis configuration and execution.
    """
    @field_validator('face_ref_img_path')
    @classmethod
    def validate_face_ref(cls, v: str, info) -> str:
        """
        Validates that the reference image path is a valid image file.
        """
        ...
    @model_validator(mode='after')
    def validate_strategy_consistency(self) -> 'PreAnalysisEvent':
        """
        Ensures that dependent settings (like face filter) are consistent with available data.
        """
        ...

class PropagationEvent(UIEvent):
    """
    Data model for the mask propagation stage.
    """
    ...

class FilterEvent(UIEvent):
    """
    Data model for filtering and gallery update events.
    """
    ...

class ExportEvent(UIEvent):
    """
    Data model for exporting filtered frames.
    """
    ...

class SessionLoadEvent(UIEvent):
    """
    Data model for loading a previous session.
    """
    ...

```

### `ðŸ“„ core/export.py`

```python
from __future__ import annotations
import subprocess
import shutil
import cv2
import numpy as np
import json
from datetime import datetime
from pathlib import Path
from typing import Optional, TYPE_CHECKING
from core.filtering import apply_all_filters_vectorized
from core.events import ExportEvent

def _perform_ffmpeg_export(video_path: str, frames_to_extract: list, export_dir: Path, logger: 'AppLogger') -> tuple[bool, Optional[str]]:
    ...

def _rename_exported_frames(export_dir: Path, frames_to_extract: list, fn_to_orig_map: dict, logger: 'AppLogger'):
    ...

def _crop_exported_frames(kept_frames: list, export_dir: Path, crop_ars: str, crop_padding: int, masks_root: Path, logger: 'AppLogger', cancel_event) -> int:
    ...

def export_kept_frames(event: ExportEvent, config: 'Config', logger: 'AppLogger', thumbnail_manager, cancel_event) -> str:
    ...

def dry_run_export(event: ExportEvent, config: 'Config') -> str:
    ...

```

### `ðŸ“„ core/filtering.py`

```python
from __future__ import annotations
import collections
from collections import defaultdict, Counter
import io
import math
from typing import Optional, Union, List, Any, TYPE_CHECKING, Callable
import numpy as np
import cv2
import torch
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
from pathlib import Path
from skimage.metrics import structural_similarity as ssim
import lpips
from torchvision import transforms
from core.database import Database
from core.managers import get_lpips_metric

def load_and_prep_filter_data(output_dir: str, get_all_filter_keys: Callable, config: 'Config') -> tuple[list, dict]:
    """
    Loads metadata from the database and prepares histograms for the UI.
    """
    ...

def histogram_svg(hist_data: tuple, title: str='', logger: Optional['AppLogger']=None) -> str:
    """
    Generates an SVG string of a histogram plot.
    """
    ...

def build_all_metric_svgs(per_metric_values: dict, get_all_filter_keys: Callable, logger: 'AppLogger') -> dict:
    """
    Builds histogram SVGs for all available metrics.
    """
    ...

def _extract_metric_arrays(all_frames_data: list[dict], config: 'Config') -> dict:
    """
    Extracts numerical arrays for each metric from the list of frame data dicts.
    """
    ...

def _run_batched_lpips(pairs: list[tuple[int, int]], all_frames_data: list[dict], dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', output_dir: str, threshold: float, device: str='cpu'):
    """
    Runs LPIPS deduplication on a list of pairs in batches using GPU if available.
    """
    ...

def _apply_deduplication_filter(all_frames_data: list[dict], filters: dict, thumbnail_manager: 'ThumbnailManager', config: 'Config', output_dir: str) -> tuple[np.ndarray, defaultdict]:
    """
    Applies deduplication logic (pHash, SSIM, or LPIPS) to filter out similar frames.
    """
    ...

def _apply_metric_filters(all_frames_data: list[dict], metric_arrays: dict, filters: dict, config: 'Config') -> tuple[np.ndarray, defaultdict]:
    """
    Applies threshold-based filtering on scalar metrics.
    """
    ...

def apply_all_filters_vectorized(all_frames_data: list[dict], filters: dict, config: 'Config', thumbnail_manager: Optional['ThumbnailManager']=None, output_dir: Optional[str]=None) -> tuple[list, list, Counter, dict]:
    """
    Main entry point for filtering frames based on deduplication and metric thresholds.

    Returns:
    Tuple of (kept_frames, rejected_frames, rejection_counts, rejection_reasons)
    """
    ...

def _generic_dedup(all_frames_data: list[dict], dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', output_dir: str, compare_fn: Callable[[np.ndarray, np.ndarray], bool]) -> tuple[np.ndarray, defaultdict]:
    """
    Generic deduplication helper that compares adjacent frames using a custom function.
    """
    ...

def _ssim_compare(img1: np.ndarray, img2: np.ndarray, threshold: float) -> bool:
    """
    Compares two images using SSIM.
    """
    ...

def apply_ssim_dedup(all_frames_data: list[dict], filters: dict, dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', config: 'Config', output_dir: str) -> tuple[np.ndarray, defaultdict]:
    """
    Applies SSIM-based deduplication.
    """
    ...

def apply_lpips_dedup(all_frames_data: list[dict], filters: dict, dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', config: 'Config', output_dir: str) -> tuple[np.ndarray, defaultdict]:
    """
    Applies LPIPS-based deduplication.
    """
    ...

```

### `ðŸ“„ core/logger.py`

```python
"""
Logging Infrastructure for Frame Extractor & Analyzer
"""

import json
import logging
import traceback
from datetime import datetime
from pathlib import Path
from queue import Queue
from typing import Any, Dict, Optional
from pydantic import BaseModel

SUCCESS_LEVEL_NUM = 25
class LogEvent(BaseModel):
    """
    Represents a structured log entry.
    """
    ...

class ColoredFormatter(logging.Formatter):
    """
    Custom formatter that adds colors to log levels.
    """
    COLORS = {'DEBUG': '\x1b[36m', 'INFO': '\x1b[37m', 'WARNING': '\x1b[33m', 'ERROR': '\x1b[31m', 'CRITICAL': '\x1b[35m', 'SUCCESS': '\x1b[32m', 'RESET': '\x1b[0m'}
    def format(self, record: logging.LogRecord) -> str:
        """
        Formats the log record with color codes.
        """
        ...

class JsonFormatter(logging.Formatter):
    """
    Formatter that outputs logs as JSON strings.
    """
    def format(self, record: logging.LogRecord) -> str:
        """
        Formats the log record as a JSON string.
        """
        ...

class AppLogger:
    """
    A comprehensive logger for the application.
    """
    def __init__(self, config: 'Config', log_dir: Optional[Path]=None, log_to_file: bool=True, log_to_console: bool=True):
        """
        Initializes the AppLogger.

        Args:
        config: Application configuration.
        log_dir: Directory to store log files.
        log_to_file: Whether to write logs to files.
        log_to_console: Whether to print logs to the console.
        """
        ...
    def _setup_console_handler(self):
        """
        Configures the console logging handler.
        """
        ...
    def _setup_file_handlers(self):
        """
        Configures file logging handlers (plain text and JSONL).
        """
        ...
    def set_progress_queue(self, queue: Queue):
        """
        Sets the queue used for sending logs to the UI.
        """
        ...
    def _create_log_event(self, level: str, message: str, component: str, **kwargs) -> LogEvent:
        """
        Helper to create a structured LogEvent object.
        """
        ...
    def _log_event(self, event: LogEvent):
        """
        Dispatches the LogEvent to standard logging and the UI queue.
        """
        ...
    def debug(self, message: str, component: str='system', **kwargs):
        """
        Logs a debug message.
        """
        ...
    def info(self, message: str, component: str='system', **kwargs):
        """
        Logs an info message.
        """
        ...
    def warning(self, message: str, component: str='system', **kwargs):
        """
        Logs a warning message.
        """
        ...
    def error(self, message: str, component: str='system', **kwargs):
        """
        Logs an error message.
        """
        ...
    def success(self, message: str, component: str='system', **kwargs):
        """
        Logs a success message.
        """
        ...
    def critical(self, message: str, component: str='system', **kwargs):
        """
        Logs a critical error message.
        """
        ...

```

### `ðŸ“„ core/managers.py`

```python
from __future__ import annotations
import collections
from collections import OrderedDict, defaultdict
import gc
import logging
import threading
import time
import shutil
import urllib.request
from pathlib import Path
from typing import Any, Callable, Dict, Optional, Union, TYPE_CHECKING
import torch
import numpy as np
import cv2
from PIL import Image
import lpips
import yt_dlp as ytdlp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from core.utils import download_model, validate_video_file, safe_resource_cleanup
from core.error_handling import ErrorHandler

build_sam3_video_predictor = None
Sam3VideoPredictor = None
def _setup_triton_mock():
    """
    Create a mock triton module if triton is not available (Windows).
    """
    ...

_triton_mocked = _setup_triton_mock()
class ThumbnailManager:
    """
    Manages an in-memory LRU cache for image thumbnails.
    """
    def __init__(self, logger: 'AppLogger', config: 'Config'):
        """
        Initializes the manager with a configurable cache size.
        """
        ...
    def get(self, thumb_path: Path) -> Optional[np.ndarray]:
        """
        Retrieves a thumbnail from cache or loads it from disk.
        """
        ...
    def clear_cache(self):
        """
        Clears the thumbnail cache and triggers garbage collection.
        """
        ...
    def _cleanup_old_entries(self):
        ...

class ModelRegistry:
    """
    Thread-safe registry for lazy loading and caching of heavy ML models.
    """
    def __init__(self, logger: Optional['AppLogger']=None):
        ...
    def get_or_load(self, key: str, loader_fn: Callable[[], Any]) -> Any:
        """
        Retrieves a model by key, loading it via loader_fn if not present.
        """
        ...
    def clear(self):
        """
        Clears all loaded models from the registry.
        """
        ...
    def get_tracker(self, model_name: str, models_path: str, user_agent: str, retry_params: tuple, config: 'Config') -> Optional['SAM3Wrapper']:
        """
        Gets or loads the SAM3 tracker, handling CPU fallback on CUDA OOM.
        """
        ...
    def _load_tracker_impl(self, model_name: str, models_path: str, user_agent: str, retry_params: tuple, device: str, config: 'Config') -> 'SAM3Wrapper':
        ...

class SAM3Wrapper:
    """
    Wrapper for SAM3 video predictor using the official handle_request API.

    See: https://huggingface.co/facebook/sam3
    """
    def __init__(self, checkpoint_path, device='cuda'):
        ...
    def initialize(self, images, init_mask=None, bbox=None, prompt_frame_idx=0):
        """
        Initialize session with images and optional prompt.

        Args:
        images: List of PIL Images or numpy arrays
        bbox: [x, y, w, h] bounding box
        prompt_frame_idx: Index of the frame to apply the prompt to

        Returns:
        dict with 'pred_mask' key
        """
        ...
    def propagate_from(self, start_idx, direction='forward'):
        """
        Yields results starting from start_idx in the given direction.
        """
        ...
    def detect_objects(self, image_rgb: np.ndarray, text_prompt: str) -> List[dict]:
        """
        Detect objects in an image using text prompt.

        Args:
        image_rgb: RGB numpy array
        text_prompt: Text description of object to find

        Returns:
        List of detection dicts with bbox, conf, label, type
        """
        ...
    def cleanup(self):
        """
        Clean up temporary resources.
        """
        ...

thread_local = threading.local()
def get_face_landmarker(model_path: str, logger: 'AppLogger') -> vision.FaceLandmarker:
    """
    Returns a thread-local MediaPipe FaceLandmarker instance.
    """
    ...

def get_face_analyzer(model_name: str, models_path: str, det_size_tuple: tuple, logger: 'AppLogger', model_registry: 'ModelRegistry', device: str='cpu') -> 'FaceAnalysis':
    """
    Gets or loads the InsightFace FaceAnalysis app, with OOM handling.
    """
    ...

def get_lpips_metric(model_name: str='alex', device: str='cpu') -> torch.nn.Module:
    """
    Returns the LPIPS metric model.
    """
    ...

def initialize_analysis_models(params: 'AnalysisParameters', config: 'Config', logger: 'AppLogger', model_registry: 'ModelRegistry') -> dict:
    """
    Initializes all necessary analysis models based on parameters.

    Returns:
    Dictionary of initialized models (face_analyzer, ref_emb, etc.).
    """
    ...

class VideoManager:
    """
    Handles video preparation and metadata extraction.
    """
    def __init__(self, source_path: str, config: 'Config', max_resolution: Optional[str]=None):
        ...
    def prepare_video(self, logger: 'AppLogger') -> str:
        """
        Prepares the video for processing.

        Downloads it if it's a YouTube URL, or validates the local path.
        """
        ...
    @staticmethod
    def get_video_info(video_path: str) -> dict:
        """
        Extracts metadata (FPS, dimensions, frame count) from the video file.
        """
        ...

```

### `ðŸ“„ core/models.py`

```python
from __future__ import annotations
import math
from typing import Optional, List, Dict, Any, Union, Callable, TYPE_CHECKING
import numpy as np
from pydantic import BaseModel, Field, ConfigDict
import cv2
import torch
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from pathlib import Path

def _coerce(val: Any, to_type: type) -> Any:
    """
    Helper to strictly coerce values to the target type.
    """
    ...

def _sanitize_face_ref(kwargs: dict, logger: 'AppLogger') -> tuple[str, bool]:
    """
    Validates the face reference image path.
    """
    ...

class QualityConfig(BaseModel):
    """
    Configuration for quality metric normalization.
    """
    ...

class FrameMetrics(BaseModel):
    """
    Container for calculated quality scores for a frame.
    """
    ...

class Frame(BaseModel):
    """
    Represents a single video frame and its associated metadata.
    """
    model_config = ConfigDict(arbitrary_types_allowed=True)
    def calculate_quality_metrics(self, thumb_image_rgb: np.ndarray, quality_config: 'QualityConfig', logger: 'AppLogger', mask: Optional[np.ndarray]=None, niqe_metric: Optional[Callable]=None, main_config: Optional['Config']=None, face_landmarker: Optional[Callable]=None, face_bbox: Optional[List[int]]=None, metrics_to_compute: Optional[Dict[str, bool]]=None):
        """
        Computes various image quality metrics (sharpness, contrast, NIQE, etc.) for the frame.

        Args:
        thumb_image_rgb: RGB image data.
        quality_config: Configuration for metric calculation.
        logger: Application logger.
        mask: Optional boolean mask to restrict calculation to the subject.
        niqe_metric: Optional PyTorch NIQE model.
        main_config: Global app configuration.
        face_landmarker: Optional MediaPipe FaceLandmarker instance.
        face_bbox: Optional bounding box of the face.
        metrics_to_compute: Dictionary flagging which metrics to calculate.
        """
        ...

class Scene(BaseModel):
    """
    Represents a detected scene or shot in the video.
    """
    ...

class SceneState:
    """
    Wrapper to manage state transitions and updates for a Scene object.
    """
    def __init__(self, scene_data: Union[dict, Scene]):
        ...
    @property
    def data(self) -> dict:
        """
        Returns the scene data as a dictionary.
        """
        ...
    @property
    def scene(self) -> Scene:
        """
        Returns the underlying Scene object.
        """
        ...
    def set_manual_bbox(self, bbox: list[int], source: str):
        """
        Overrides the automatically selected subject bounding box.
        """
        ...
    def reset(self):
        """
        Resets the scene to its initial state (undoes manual overrides).
        """
        ...
    def include(self):
        """
        Marks the scene as included.
        """
        ...
    def exclude(self):
        """
        Marks the scene as excluded.
        """
        ...
    def update_seed_result(self, bbox: Optional[list[int]], details: dict):
        """
        Updates the seeding result (detected subject) for the scene.
        """
        ...

class AnalysisParameters(BaseModel):
    """
    Aggregates all parameters for the analysis pipeline.
    """
    @classmethod
    def from_ui(cls, logger: 'AppLogger', config: 'Config', **kwargs) -> 'AnalysisParameters':
        """
        Factory method to create parameters from UI arguments, handling validation and defaults.
        """
        ...

class MaskingResult(BaseModel):
    """
    Result of the mask propagation process for a frame.
    """
    ...

```

### `ðŸ“„ core/pipelines.py`

```python
from __future__ import annotations
import math
import threading
import subprocess
import time
import re
import os
import shutil
import json
import torch
from collections import deque
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from queue import Queue, Empty
from typing import Optional, List, Dict, Any, Generator, Callable, TYPE_CHECKING
from dataclasses import fields
from core.models import AnalysisParameters, Scene, Frame
from core.utils import handle_common_errors, estimate_totals, sanitize_filename, _to_json_safe, monitor_memory_usage, validate_video_file, safe_resource_cleanup, create_frame_map
from core.managers import VideoManager, initialize_analysis_models
from core.scene_utils import SubjectMasker, save_scene_seeds, get_scene_status_text, run_scene_detection, make_photo_thumbs
from core.filtering import load_and_prep_filter_data, apply_all_filters_vectorized
from core.database import Database
from core.events import ExtractionEvent, PreAnalysisEvent, PropagationEvent, SessionLoadEvent, ExportEvent
from core.error_handling import ErrorHandler
from core.progress import AdvancedProgressTracker

def _process_ffmpeg_stream(stream, tracker: Optional['AdvancedProgressTracker'], desc: str, total_duration_s: float):
    """
    Parses FFmpeg progress stream and updates the tracker.
    """
    ...

def _process_ffmpeg_showinfo(stream) -> tuple[list, str]:
    """
    Parses FFmpeg stderr for 'showinfo' frame numbers.
    """
    ...

def run_ffmpeg_extraction(video_path: str, output_dir: Path, video_info: dict, params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, logger: 'AppLogger', config: 'Config', tracker: Optional['AdvancedProgressTracker']=None):
    """
    Executes FFmpeg command to extract frames/thumbnails.

    Constructs complex filter chains based on extraction method (interval, keyframes, etc.).
    """
    ...

class Pipeline:
    """
    Base class for processing pipelines.
    """
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event):
        ...

class ExtractionPipeline(Pipeline):
    """
    Pipeline for extracting frames from video or processing image folders.
    """
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event):
        ...
    def _run_impl(self, tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """
        Internal execution logic for extraction.
        """
        ...

class AnalysisPipeline(Pipeline):
    """
    Pipeline for analyzing frames (pre-analysis, propagation, full analysis).
    """
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'):
        ...
    def _initialize_niqe_metric(self):
        """
        Lazy initialization of the NIQE metric model.
        """
        ...
    def run_full_analysis(self, scenes_to_process: list['Scene'], tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """
        Runs the mask propagation phase.

        Despite the name, this currently focuses on propagation (subject masking) for video,
        or full processing for image folders.
        """
        ...
    def run_analysis_only(self, scenes_to_process: list['Scene'], tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """
        Runs the frame analysis phase (calculating quality metrics).

        This phase consumes the masks generated in the propagation phase.
        """
        ...
    def _filter_completed_scenes(self, scenes: list['Scene'], progress_data: dict) -> list['Scene']:
        """
        Removes scenes that have already been processed when resuming.
        """
        ...
    def _save_progress(self, current_scene: 'Scene', progress_file: Path):
        """
        Updates the progress file with the completed scene ID.
        """
        ...
    def _process_reference_face(self):
        """
        Computes the embedding for the reference face image.
        """
        ...
    def _run_image_folder_analysis(self, tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """
        Specialized execution path for image folder inputs.
        """
        ...
    def _run_analysis_loop(self, scenes_to_process: list['Scene'], metrics_to_compute: dict, tracker: Optional['AdvancedProgressTracker']=None):
        """
        Orchestrates the parallel processing of frames for metric calculation.
        """
        ...
    def _process_batch(self, batch_paths: list[Path], metrics_to_compute: dict) -> int:
        """
        Processes a batch of frame files.
        """
        ...
    def _process_single_frame(self, thumb_path: Path, metrics_to_compute: dict):
        """
        Analyzes a single frame: computes metrics, face similarity, and stores metadata.
        """
        ...
    def _analyze_face_similarity(self, frame: 'Frame', image_rgb: np.ndarray) -> Optional[list[int]]:
        """
        Computes face similarity and confidence against the reference face.
        """
        ...

@handle_common_errors
def execute_extraction(event: 'ExtractionEvent', progress_queue: Queue, cancel_event: threading.Event, logger: 'AppLogger', config: 'Config', thumbnail_manager: Optional['ThumbnailManager']=None, cuda_available: Optional[bool]=None, progress: Optional[Callable]=None, model_registry: Optional['ModelRegistry']=None) -> Generator[dict, None, None]:
    """
    Orchestrates the frame extraction process.

    Handlers file uploads, parameter validation, and running the extraction pipeline.
    """
    ...

@handle_common_errors
def execute_pre_analysis(event: 'PreAnalysisEvent', progress_queue: Queue, cancel_event: threading.Event, logger: 'AppLogger', config: 'Config', thumbnail_manager: 'ThumbnailManager', cuda_available: bool, progress: Optional[Callable]=None, model_registry: 'ModelRegistry'=None) -> Generator[dict, None, None]:
    """
    Orchestrates the pre-analysis phase (scene detection, subject seeding).
    """
    ...

def validate_session_dir(path: Union[str, Path]) -> tuple[Optional[Path], Optional[str]]:
    """
    Checks if the provided path is a valid session directory.
    """
    ...

def execute_session_load(event: 'SessionLoadEvent', logger: 'AppLogger') -> dict:
    """
    Loads session state from disk.

    Verifies the directory structure and loads configuration, scenes, and metadata.
    """
    ...

def execute_propagation(event: PropagationEvent, progress_queue: Queue, cancel_event: threading.Event, logger: AppLogger, config: Config, thumbnail_manager, cuda_available, progress=None, model_registry: 'ModelRegistry'=None) -> Generator[dict, None, None]:
    """
    Orchestrates the mask propagation stage.
    """
    ...

@handle_common_errors
def execute_analysis(event: PropagationEvent, progress_queue: Queue, cancel_event: threading.Event, logger: AppLogger, config: Config, thumbnail_manager, cuda_available, progress=None, model_registry: 'ModelRegistry'=None) -> Generator[dict, None, None]:
    """
    Orchestrates the frame analysis stage.
    """
    ...

```

### `ðŸ“„ core/progress.py`

```python
"""
Progress Tracking Infrastructure for Frame Extractor & Analyzer
"""

import threading
import time
from queue import Queue
from typing import Callable, Optional
from pydantic import BaseModel

class ProgressEvent(BaseModel):
    ...

class AdvancedProgressTracker:
    """
    Tracks and estimates progress for long-running operations.

    Calculates ETA using exponential moving average (EMA) and updates the UI.
    """
    def __init__(self, progress: Callable, queue: Queue, logger: 'AppLogger', ui_stage_name: str=''):
        """
        Initializes the progress tracker.

        Args:
        progress: Gradio progress callback.
        queue: Queue for sending progress events.
        logger: Application logger.
        ui_stage_name: Initial stage name.
        """
        ...
    def start(self, total_items: int, desc: Optional[str]=None):
        """
        Resets the tracker for a new operation.
        """
        ...
    def step(self, n: int=1, desc: Optional[str]=None, substage: Optional[str]=None):
        """
        Increments progress by 'n' steps.

        Args:
        n: Number of steps completed.
        desc: Optional stage description update.
        substage: Optional substage description update.
        """
        ...
    def set(self, done: int, desc: Optional[str]=None, substage: Optional[str]=None):
        """
        Sets the absolute number of completed steps.
        """
        ...
    def set_stage(self, stage: str, substage: Optional[str]=None):
        """
        Updates the current stage description without changing progress.
        """
        ...
    def done_stage(self, final_text: Optional[str]=None):
        """
        Marks the current operation as complete.
        """
        ...
    def _overlay(self, force: bool=False):
        """
        Emits a progress update if enough time has passed (throttling).
        """
        ...
    def _eta_seconds(self) -> Optional[float]:
        """
        Calculates estimated seconds remaining based on EMA.
        """
        ...
    @staticmethod
    def _fmt_eta(eta_s: Optional[float]) -> str:
        """
        Formats seconds into a human-readable string.
        """
        ...

```

### `ðŸ“„ core/sam3_patches.py`

```python
"""
SAM3 Compatibility Patches for Windows

Provides fallback implementations for SAM3 operations that require Triton,
which is not available on Windows.
"""

import cv2
import numpy as np
import torch

def edt_triton_fallback(data):
    """
    OpenCV-based fallback for Euclidean Distance Transform when Triton unavailable
    """
    ...

def connected_components_fallback(input_tensor):
    """
    CPU-based fallback for connected components when Triton unavailable
    """
    ...

def apply_patches():
    """
    Apply monkey patches to SAM3 if Triton is not available
    """
    ...

```

### `ðŸ“„ core/scene_utils/__init__.py`

```python
"""
Scene utilities package for Frame Extractor & Analyzer.

This package provides scene detection, seed selection, mask propagation,
and related utilities. All public symbols are re-exported for backward
compatibility.

Example usage:
    from core.scene_utils import SubjectMasker, run_scene_detection
    from core.scene_utils import MaskPropagator, SeedSelector
"""

from __future__ import annotations
from core.scene_utils.detection import run_scene_detection, make_photo_thumbs
from core.scene_utils.mask_propagator import MaskPropagator
from core.scene_utils.seed_selector import SeedSelector
from core.scene_utils.subject_masker import SubjectMasker
from core.scene_utils.helpers import draw_boxes_preview, save_scene_seeds, get_scene_status_text, toggle_scene_status, _create_analysis_context, _recompute_single_preview, _wire_recompute_handler

__all__ = ['run_scene_detection', 'make_photo_thumbs', 'MaskPropagator', 'SeedSelector', 'SubjectMasker', 'draw_boxes_preview', 'save_scene_seeds', 'get_scene_status_text', 'toggle_scene_status', '_create_analysis_context', '_recompute_single_preview', '_wire_recompute_handler']
```

### `ðŸ“„ core/scene_utils/detection.py`

```python
"""
Scene detection and thumbnail generation utilities.
"""

from __future__ import annotations
import math
import json
from typing import Optional, TYPE_CHECKING
from pathlib import Path
import numpy as np
import cv2
from PIL import Image
from scenedetect import detect, ContentDetector

def run_scene_detection(video_path: str, output_dir: Path, logger: 'AppLogger') -> list:
    """
    Detect scene changes in a video using PySceneDetect.

    Args:
    video_path: Path to the video file
    output_dir: Directory to save scenes.json
    logger: Application logger

    Returns:
    List of (start_frame, end_frame) tuples for each scene
    """
    ...

def make_photo_thumbs(image_paths: list[Path], out_dir: Path, params: 'AnalysisParameters', cfg: 'Config', logger: 'AppLogger', tracker: Optional['AdvancedProgressTracker']=None) -> dict:
    """
    Generate thumbnails for a list of images.

    Args:
    image_paths: List of paths to source images
    out_dir: Output directory for thumbnails
    params: Analysis parameters containing thumb_megapixels
    cfg: Application configuration
    logger: Application logger
    tracker: Optional progress tracker

    Returns:
    Dictionary mapping frame numbers to thumbnail filenames
    """
    ...

```

### `ðŸ“„ core/scene_utils/helpers.py`

```python
"""
Helper functions for scene processing.
"""

from __future__ import annotations
import json
import threading
from typing import Optional, Any, TYPE_CHECKING
from pathlib import Path
from queue import Queue
import numpy as np
import cv2
from PIL import Image
from core.utils import create_frame_map, render_mask_overlay, draw_bbox, _to_json_safe
from core.managers import initialize_analysis_models
from core.scene_utils.subject_masker import SubjectMasker
from core.shared import build_scene_gallery_items

def draw_boxes_preview(img: np.ndarray, boxes_xyxy: list[list[int]], cfg: 'Config') -> np.ndarray:
    """
    Draw bounding boxes on an image for preview.

    Args:
    img: RGB image
    boxes_xyxy: List of boxes in [x1, y1, x2, y2] format
    cfg: Config with visualization settings

    Returns:
    Image with boxes drawn
    """
    ...

def save_scene_seeds(scenes_list: list['Scene'], output_dir_str: str, logger: 'AppLogger') -> None:
    """
    Save scene seed information to JSON file.

    Args:
    scenes_list: List of Scene objects
    output_dir_str: Output directory path
    logger: Application logger
    """
    ...

def get_scene_status_text(scenes_list: list['Scene']) -> tuple[str, Any]:
    """
    Generate status text and button update for scene list.

    Args:
    scenes_list: List of Scene objects

    Returns:
    Tuple of (status_text, gr.update for button)
    """
    ...

def toggle_scene_status(scenes_list: list['Scene'], selected_shot_id: int, new_status: str, output_folder: str, logger: 'AppLogger') -> tuple[list, str, str, Any]:
    """
    Toggle the status of a selected scene.

    Args:
    scenes_list: List of Scene objects
    selected_shot_id: ID of the scene to toggle
    new_status: New status ('included' or 'excluded')
    output_folder: Output folder path
    logger: Application logger

    Returns:
    Tuple of (updated_scenes, status_text, message, button_update)
    """
    ...

def _create_analysis_context(config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager', cuda_available: bool, ana_ui_map_keys: list[str], ana_input_components: list, model_registry: 'ModelRegistry') -> 'SubjectMasker':
    """
    Helper to initialize a SubjectMasker from UI arguments.
    """
    ...

def _recompute_single_preview(scene_state: 'SceneState', masker: 'SubjectMasker', overrides: dict, thumbnail_manager: 'ThumbnailManager', logger: 'AppLogger'):
    """
    Re-runs the seeding process for a single scene and updates its preview image.
    """
    ...

def _wire_recompute_handler(config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager', scenes: list['Scene'], shot_id: int, outdir: str, text_prompt: str, view: str, ana_ui_map_keys: list[str], ana_input_components: list, cuda_available: bool, model_registry: 'ModelRegistry') -> tuple:
    """
    Gradio event handler for the 'Recompute' button in the scene editor.
    """
    ...

```

### `ðŸ“„ core/scene_utils/mask_propagator.py`

```python
"""
MaskPropagator class for propagating segmentation masks across video frames.
"""

from __future__ import annotations
import threading
from typing import Optional, TYPE_CHECKING
from queue import Queue
import numpy as np
import torch
from core.utils import rgb_to_pil, postprocess_mask

class MaskPropagator:
    """
    Propagates segmentation masks from a seed frame to surrounding frames.

    Uses SAM3 (Segment Anything Model 3) to propagate masks forward and backward
    from a seed frame where the subject was initially identified.
    """
    def __init__(self, params: 'AnalysisParameters', dam_tracker: 'SAM3Wrapper', cancel_event: threading.Event, progress_queue: Queue, config: 'Config', logger: 'AppLogger', device: str='cpu'):
        """
        Initialize the MaskPropagator.

        Args:
        params: Analysis parameters
        dam_tracker: SAM3 wrapper for mask prediction
        cancel_event: Event to signal cancellation
        progress_queue: Queue for progress updates
        config: Application configuration
        logger: Application logger
        device: Device to run on ('cpu' or 'cuda')
        """
        ...
    def propagate(self, shot_frames_rgb: list[np.ndarray], seed_idx: int, bbox_xywh: list[int], tracker: Optional['AdvancedProgressTracker']=None) -> tuple[list, list, list, list]:
        """
        Propagate masks from a seed frame to all frames in a shot.

        Args:
        shot_frames_rgb: List of RGB frames as numpy arrays
        seed_idx: Index of the seed frame in the list
        bbox_xywh: Bounding box [x, y, width, height] on the seed frame
        tracker: Optional progress tracker

        Returns:
        Tuple of (masks, area_percentages, is_empty_flags, error_messages)
        """
        ...

```

### `ðŸ“„ core/scene_utils/seed_selector.py`

```python
"""
SeedSelector class for selecting seed frames and bounding boxes for mask propagation.
"""

from __future__ import annotations
import math
from typing import Optional, Union, Any, TYPE_CHECKING
import numpy as np
import cv2
import torch
from core.utils import rgb_to_pil, postprocess_mask

class SeedSelector:
    """
    Selects seed frames and bounding boxes for mask propagation.

    Supports multiple strategies:
    - Identity-first (face matching)
    - Object-first (text prompt)
    - Face + text fallback
    - Automatic (person detection with various scoring)
    """
    def __init__(self, params: 'AnalysisParameters', config: 'Config', face_analyzer: 'FaceAnalysis', reference_embedding: np.ndarray, tracker: 'SAM3Wrapper', logger: 'AppLogger', device: str='cpu'):
        """
        Initialize the SeedSelector.

        Args:
        params: Analysis parameters
        config: Application configuration
        face_analyzer: InsightFace analyzer for face detection/recognition
        reference_embedding: Reference face embedding for identity matching
        tracker: SAM3 wrapper for object detection
        logger: Application logger
        device: Device to run on ('cpu' or 'cuda')
        """
        ...
    def _get_param(self, source: Union[dict, object], key: str, default: Any=None) -> Any:
        """
        Get a parameter from either a dict or an object.
        """
        ...
    def select_seed(self, frame_rgb: np.ndarray, current_params: Optional[dict]=None, scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """
        Select a seed bounding box for the given frame.

        Args:
        frame_rgb: RGB frame as numpy array
        current_params: Optional override parameters
        scene: Optional scene context

        Returns:
        Tuple of (bbox_xywh, details_dict)
        """
        ...
    def _face_with_text_fallback_seed(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """
        Try face-first, fall back to text prompt if face not found.
        """
        ...
    def _identity_first_seed(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """
        Find subject by matching to reference face.
        """
        ...
    def _object_first_seed(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """
        Find subject using text prompt, validated by person detection.
        """
        ...
    def _find_target_face(self, frame_rgb: np.ndarray) -> tuple[Optional[dict], dict]:
        """
        Find the target face in frame that matches reference embedding.
        """
        ...
    def _get_person_boxes(self, frame_rgb: np.ndarray, scene: Optional['Scene']=None) -> list[dict]:
        """
        Get person bounding boxes from scene cache or detection.
        """
        ...
    def _get_text_prompt_boxes(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters']) -> tuple[list[dict], dict]:
        """
        Get bounding boxes from text prompt detection.
        """
        ...
    def _score_and_select_candidate(self, target_face: dict, person_boxes: list[dict], text_boxes: list[dict]) -> tuple[Optional[list], dict]:
        """
        Score and select the best candidate box that contains the target face.
        """
        ...
    def _choose_person_by_strategy(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[list, dict]:
        """
        Select person using configurable strategy.
        """
        ...
    def _load_image_from_array(self, image_rgb: np.ndarray) -> tuple[np.ndarray, torch.Tensor]:
        """
        Load image for model input.
        """
        ...
    def _calculate_iou(self, box1: list, box2: list) -> float:
        """
        Calculate IoU between two boxes in xyxy format.
        """
        ...
    def _box_contains(self, cb: list, ib: list) -> bool:
        """
        Check if container box (cb) contains inner box (ib).
        """
        ...
    def _expand_face_to_body(self, face_bbox: list, img_shape: tuple) -> list[int]:
        """
        Expand a face bounding box to approximate body bounding box.
        """
        ...
    def _final_fallback_box(self, img_shape: tuple) -> list[int]:
        """
        Return a fallback bounding box when no subject is found.
        """
        ...
    def _xyxy_to_xywh(self, box: list) -> list[int]:
        """
        Convert box from xyxy to xywh format.
        """
        ...
    def _sam2_mask_for_bbox(self, frame_rgb_small: np.ndarray, bbox_xywh: list) -> Optional[np.ndarray]:
        """
        Generate a mask for the given bounding box using SAM3.
        """
        ...

```

### `ðŸ“„ core/scene_utils/subject_masker.py`

```python
"""
SubjectMasker class for coordinating subject detection and mask propagation.
"""

from __future__ import annotations
import threading
import json
from typing import Optional, Callable, TYPE_CHECKING
from queue import Queue
from pathlib import Path
import numpy as np
import cv2
import torch
from core.utils import create_frame_map, draw_bbox
from core.scene_utils.mask_propagator import MaskPropagator
from core.scene_utils.seed_selector import SeedSelector

class SubjectMasker:
    """
    Coordinates subject detection and mask propagation for video frames.

    This class orchestrates:
    - SAM3 tracker initialization
    - Seed frame selection
    - Bounding box detection via SeedSelector
    - Mask propagation via MaskPropagator
    """
    def __init__(self, params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, config: 'Config', frame_map: Optional[dict]=None, face_analyzer: Optional['FaceAnalysis']=None, reference_embedding: Optional[np.ndarray]=None, thumbnail_manager: Optional['ThumbnailManager']=None, niqe_metric: Optional[Callable]=None, logger: Optional['AppLogger']=None, face_landmarker: Optional['FaceLandmarker']=None, device: str='cpu', model_registry: 'ModelRegistry'=None):
        """
        Initialize SubjectMasker.

        Args:
        params: Analysis parameters
        progress_queue: Queue for progress updates
        cancel_event: Event to signal cancellation
        config: Application configuration
        frame_map: Optional pre-loaded frame map
        face_analyzer: Optional InsightFace analyzer
        reference_embedding: Optional reference face embedding
        thumbnail_manager: Optional thumbnail cache manager
        niqe_metric: Optional NIQE quality metric
        logger: Application logger
        face_landmarker: Optional MediaPipe face landmarker
        device: Device for computation ('cpu' or 'cuda')
        model_registry: Model registry for loading SAM3
        """
        ...
    def initialize_models(self) -> None:
        """
        Initialize required models based on parameters.
        """
        ...
    def _initialize_tracker(self) -> bool:
        """
        Initialize the SAM3 tracker.

        Returns:
        True if initialization successful, False otherwise
        """
        ...
    def run_propagation(self, frames_dir: str, scenes_to_process: list['Scene'], tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """
        Run mask propagation for all scenes.

        Args:
        frames_dir: Directory containing extracted frames
        scenes_to_process: List of scenes to process
        tracker: Optional progress tracker

        Returns:
        Dictionary mapping frame filenames to mask metadata
        """
        ...
    def _load_shot_frames(self, frames_dir: str, thumb_dir: Path, start: int, end: int) -> list[tuple[int, np.ndarray, tuple[int, int]]]:
        """
        Load frames for a shot from disk.

        Args:
        frames_dir: Base frames directory
        thumb_dir: Thumbnails directory
        start: Start frame number
        end: End frame number

        Returns:
        List of (frame_number, thumbnail_rgb, (height, width)) tuples
        """
        ...
    def _select_best_frame_in_scene(self, scene: 'Scene', frames_dir: str) -> None:
        """
        Select the best frame in a scene for seeding.

        Uses NIQE quality metric and face similarity if available.

        Args:
        scene: Scene to process
        frames_dir: Frames directory
        """
        ...
    def get_seed_for_frame(self, frame_rgb: np.ndarray, seed_config: dict=None, scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """
        Get seed bounding box for a frame.

        Args:
        frame_rgb: RGB frame as numpy array
        seed_config: Optional seed configuration override
        scene: Optional scene context

        Returns:
        Tuple of (bbox_xywh, details_dict)
        """
        ...
    def get_mask_for_bbox(self, frame_rgb_small: np.ndarray, bbox_xywh: list) -> Optional[np.ndarray]:
        """
        Generate a mask for a bounding box.

        Args:
        frame_rgb_small: RGB frame
        bbox_xywh: Bounding box in [x, y, w, h] format

        Returns:
        Mask as numpy array or None
        """
        ...
    def draw_bbox(self, img_rgb: np.ndarray, xywh: list, color: Optional[tuple]=None, thickness: Optional[int]=None, label: Optional[str]=None) -> np.ndarray:
        """
        Draw a bounding box on an image.
        """
        ...
    def _create_frame_map(self, output_dir: str) -> dict:
        """
        Create a frame map for the output directory.
        """
        ...

```

### `ðŸ“„ core/shared.py`

```python
"""
Shared utilities for Frame Extractor & Analyzer

This module contains pure functions that are shared between core and UI modules,
resolving circular import issues.
"""

from __future__ import annotations
import cv2
import numpy as np
from pathlib import Path
from typing import TYPE_CHECKING, Optional, Union, List, Tuple, Any

def scene_matches_view(scene: 'Scene', view: str) -> bool:
    """
    Check if a scene matches the specified view filter.
    
    Args:
    scene: Scene object to check
    view: One of "All", "Kept", or "Rejected"
    
    Returns:
    True if the scene matches the view filter
    """
    ...

def create_scene_thumbnail_with_badge(thumb_img: np.ndarray, scene_idx: int, is_excluded: bool) -> np.ndarray:
    """
    Create a scene thumbnail with a visual badge indicating exclusion status.
    
    Args:
    thumb_img: RGB thumbnail image
    scene_idx: Index of the scene
    is_excluded: Whether the scene is excluded
    
    Returns:
    Thumbnail with badge overlay
    """
    ...

def scene_caption(scene: Union[dict, 'Scene']) -> str:
    """
    Generate a caption string for a scene.
    
    Args:
    scene: Scene object or dict
    
    Returns:
    Caption string with scene ID, frame range, and status
    """
    ...

def build_scene_gallery_items(scenes: List[Union[dict, 'Scene']], view: str, output_dir: str, page_num: int=1, page_size: int=20) -> Tuple[List[Tuple], List[int], int]:
    """
    Build gallery items for scene display.
    
    This function is moved from ui/gallery_utils.py to break the circular
    import between core/pipelines.py and ui/gallery_utils.py.
    
    Args:
    scenes: List of Scene objects or dicts
    view: View filter ("All", "Kept", "Rejected")
    output_dir: Path to output directory
    page_num: Current page number (1-indexed)
    page_size: Items per page
    
    Returns:
    Tuple of (gallery_items, index_map, total_pages)
    """
    ...

```

### `ðŸ“„ core/utils.py`

```python
from __future__ import annotations
import contextlib
import cv2
import functools
import gc
import hashlib
import json
import logging
import math
import numpy as np
import os
import re
import shutil
import traceback
import urllib.request
import urllib.error
from pathlib import Path
from typing import Any, Callable, Optional, Union, TYPE_CHECKING
import torch
from numba import njit
from pydantic import BaseModel
from PIL import Image

def handle_common_errors(func: Callable) -> Callable:
    """
    Decorator to catch common exceptions and return a standardized error dictionary.
    """
    ...

def monitor_memory_usage(logger: 'AppLogger', device: str, threshold_mb: int=8000):
    """
    Logs a warning and clears cache if GPU memory usage exceeds threshold.
    """
    ...

def validate_video_file(video_path: str):
    """
    Checks if the video file exists, is not empty, and can be opened by OpenCV.
    """
    ...

def estimate_totals(params: 'AnalysisParameters', video_info: dict, scenes: Optional[list['Scene']]) -> dict:
    """
    Estimates the total work items for each pipeline stage.
    """
    ...

def sanitize_filename(name: str, config: 'Config', max_length: Optional[int]=None) -> str:
    """
    Sanitizes a string to be safe for use as a filename.
    """
    ...

def _to_json_safe(obj: Any) -> Any:
    """
    Recursively converts objects (NumPy types, Path, etc.) to JSON-serializable types.
    """
    ...

@contextlib.contextmanager
def safe_resource_cleanup(device: str='cpu'):
    """
    Context manager to ensure garbage collection and CUDA cache clearing.
    """
    ...

def is_image_folder(p: Union[str, Path]) -> bool:
    """
    Checks if the path points to a directory.
    """
    ...

def list_images(p: Union[str, Path], cfg: Config) -> list[Path]:
    """
    Lists all valid image files in a directory.
    """
    ...

@njit
def compute_entropy(hist: np.ndarray, entropy_norm: float) -> float:
    """
    Computes normalized entropy from a histogram using Numba.
    """
    ...

def _compute_sha256(path: Path) -> str:
    """
    Computes SHA256 hash of a file.
    """
    ...

def download_model(url: str, dest_path: Union[str, Path], description: str, logger: 'AppLogger', error_handler: 'ErrorHandler', user_agent: str, min_size: int=1000000, expected_sha256: Optional[str]=None, token: Optional[str]=None):
    """
    Downloads a file from a URL with retries, validation, and progress logging.
    """
    ...

def postprocess_mask(mask: np.ndarray, config: 'Config', fill_holes: bool=True, keep_largest_only: bool=True) -> np.ndarray:
    """
    Cleans up binary masks using morphological operations and connected components.
    """
    ...

def render_mask_overlay(frame_rgb: np.ndarray, mask_gray: np.ndarray, alpha: float, logger: 'AppLogger') -> np.ndarray:
    """
    overlays a semi-transparent red mask on the image.
    """
    ...

def rgb_to_pil(image_rgb: np.ndarray) -> Image.Image:
    """
    Converts a NumPy RGB array to a PIL Image.
    """
    ...

def create_frame_map(output_dir: Path, logger: 'AppLogger', ext: str='.webp') -> dict:
    """
    Creates a mapping from original frame numbers to extracted filenames.
    """
    ...

def draw_bbox(img_rgb: np.ndarray, xywh: list, config: 'Config', color: Optional[tuple]=None, thickness: Optional[int]=None, label: Optional[str]=None) -> np.ndarray:
    """
    Draws a bounding box and optional label on an image.
    """
    ...

```

### `ðŸ“„ tests/conftest.py`

```python
"""
Centralized pytest fixtures for Frame Extractor & Analyzer tests.

This module provides reusable mock fixtures for testing, avoiding duplication
across test files and improving test maintainability.
"""

import sys
import os
import pytest
from unittest.mock import MagicMock, patch
from pathlib import Path
import numpy as np
import pydantic

def _create_mock_torch():
    """
    Create a comprehensive mock for torch and its submodules.
    """
    ...

def _create_mock_torch_submodules(mock_torch):
    """
    Create mocks for torch submodules like nn, optim, utils.
    """
    ...

def _create_mock_torchvision():
    """
    Create a mock for torchvision.
    """
    ...

def _create_mock_psutil():
    """
    Create a mock for psutil with expected return values.
    """
    ...

def _create_mock_matplotlib():
    """
    Create a mock for matplotlib.
    """
    ...

def build_modules_to_mock():
    """
    Build the complete dictionary of modules to mock.
    """
    ...

MODULES_TO_MOCK = build_modules_to_mock()
@pytest.fixture(scope='session')
def mock_torch():
    """
    Session-scoped mock for torch module.
    """
    ...

@pytest.fixture
def mock_config(tmp_path):
    """
    Provides a test Config with temporary directories.
    
    Use this for tests that need a valid Config object
    with writable paths.
    """
    ...

@pytest.fixture
def mock_logger(mock_config):
    """
    Provides a mock AppLogger for testing.
    """
    ...

@pytest.fixture
def mock_thumbnail_manager(mock_logger, mock_config):
    """
    Provides a mock ThumbnailManager.
    """
    ...

@pytest.fixture
def mock_model_registry(mock_logger):
    """
    Provides a mock ModelRegistry.
    """
    ...

@pytest.fixture
def mock_progress_queue():
    """
    Provides a mock progress queue.
    """
    ...

@pytest.fixture
def mock_cancel_event():
    """
    Provides a mock cancel event.
    """
    ...

@pytest.fixture
def mock_ui_state():
    """
    Provides a dictionary with default values for UI-related event models.
    
    Useful for testing event validation and pipeline execution.
    """
    ...

@pytest.fixture
def sample_frames_data():
    """
    Provides sample frame metadata for filtering tests.
    
    Includes a mix of good and bad frames to test various filters.
    """
    ...

@pytest.fixture
def sample_scenes():
    """
    Provides sample Scene objects for scene-related tests.
    """
    ...

@pytest.fixture
def sample_image_rgb():
    """
    Provides a sample RGB image for testing.
    """
    ...

@pytest.fixture
def sample_mask():
    """
    Provides a sample binary mask for testing.
    """
    ...

```

### `ðŸ“„ tests/e2e/test_app_flow.py`

```python
import pytest
from playwright.sync_api import Page, expect
import subprocess
import time
import signal
import sys
from pathlib import Path
from os import environ

PORT = 7860
BASE_URL = f'http://127.0.0.1:{PORT}'
@pytest.fixture(scope='module')
def app_server():
    """
    Starts the mock app server before tests and kills it after.
    """
    ...

def test_full_user_flow(page: Page, app_server):
    """
    Tests the complete end-to-end workflow:
    Extraction -> Pre-Analysis -> Scene Selection -> Propagation -> Analysis -> Export
    """
    ...

```

### `ðŸ“„ tests/mock_app.py`

```python
import sys
import os
import threading
import time
from unittest.mock import MagicMock, patch
import app
from app import Config, AppLogger, ThumbnailManager
import core.pipelines
import core.utils
import core.managers
from core.models import Scene

mock_torch = MagicMock(name='torch')
mock_torch.cuda.is_available.return_value = False
mock_torch.__version__ = '2.0.0'
mock_torch.nn.Module = MagicMock
mock_torch.Tensor = MagicMock
mock_sam3 = MagicMock(name='sam3')
mock_sam3.model_builder = MagicMock()
modules_to_mock = {'torch': mock_torch, 'torchvision': MagicMock(), 'torchvision.ops': MagicMock(), 'torchvision.transforms': MagicMock(), 'insightface': MagicMock(), 'insightface.app': MagicMock(), 'sam3': mock_sam3, 'sam3.model_builder': mock_sam3.model_builder, 'sam3.model.sam3_video_predictor': MagicMock(), 'mediapipe': MagicMock(), 'mediapipe.tasks': MagicMock(), 'mediapipe.tasks.python': MagicMock(), 'mediapipe.tasks.python.vision': MagicMock(), 'pyiqa': MagicMock(), 'scenedetect': MagicMock(), 'yt_dlp': MagicMock(), 'ultralytics': MagicMock(), 'groundingdino': MagicMock(), 'numba': MagicMock(), 'lpips': MagicMock()}
def mock_extraction_run(self, tracker=None):
    """
    Mocks the extraction process.
    """
    ...

def mock_pre_analysis_execution(event, progress_queue, cancel_event, logger, config, thumbnail_manager, cuda_available, progress=None, model_registry=None):
    """
    Mocks execute_pre_analysis generator.
    """
    ...

def mock_propagation_execution(event, progress_queue, cancel_event, logger, config, thumbnail_manager, cuda_available, progress=None, model_registry=None):
    ...

def mock_analysis_execution(event, progress_queue, cancel_event, logger, config, thumbnail_manager, cuda_available, progress=None, model_registry=None):
    ...

core.pipelines.ExtractionPipeline._run_impl = mock_extraction_run
core.pipelines.execute_pre_analysis = mock_pre_analysis_execution
core.pipelines.execute_propagation = mock_propagation_execution
core.pipelines.execute_analysis = mock_analysis_execution
core.utils.download_model = MagicMock()
core.managers.download_model = MagicMock()
```

### `ðŸ“„ tests/test_batch_manager.py`

```python
import time
import pytest
from core.batch_manager import BatchManager, BatchStatus, BatchItem

def test_batch_manager_add():
    ...

def test_batch_manager_processing():
    ...

def test_batch_manager_failure():
    ...

```

### `ðŸ“„ tests/test_core.py`

```python
import pytest
from pydantic import ValidationError
import sys
import unittest
from unittest.mock import MagicMock, patch, mock_open
from pathlib import Path
import json
import time
import numpy as np
import gradio as gr
import cv2
import datetime
from collections import deque
import pydantic
from core.config import Config
from core.database import Database
from core.logger import AppLogger
from core.models import Scene, Frame, QualityConfig, _coerce
from core.filtering import apply_all_filters_vectorized
from ui.gallery_utils import auto_set_thresholds
from core.events import PreAnalysisEvent

mock_torch = MagicMock(name='torch')
mock_torch.__version__ = '2.0.0'
mock_torch.__path__ = ['fake']
mock_torch.__spec__ = MagicMock()
mock_torch.hub = MagicMock(name='torch.hub')
mock_torch.cuda = MagicMock(name='torch.cuda')
mock_torch.cuda.is_available.return_value = False
mock_torch.distributed = MagicMock(name='torch.distributed')
mock_torch.multiprocessing = MagicMock(name='torch.multiprocessing')
mock_torch.amp = MagicMock(name='torch.amp')
mock_torch_autograd = MagicMock(name='torch.autograd')
mock_torch_autograd.Variable = MagicMock(name='torch.autograd.Variable')
mock_torch_nn = MagicMock(name='torch.nn')
mock_torch_nn.__path__ = ['fake']
class MockNNModule:
    def __init__(self, *args, **kwargs):
        ...
    def __call__(self, *args, **kwargs):
        ...

mock_torch_nn.Module = MockNNModule
mock_torch_nn.attention = MagicMock(name='torch.nn.attention')
mock_torch_nn_init = MagicMock(name='torch.nn.init')
mock_torch_nn_functional = MagicMock(name='torch.nn.functional')
mock_torch_optim = MagicMock(name='torch.optim')
mock_torch_utils = MagicMock(name='torch.utils')
mock_torch_utils.__path__ = ['fake']
mock_torch_utils_data = MagicMock(name='torch.utils.data')
mock_torch_utils_checkpoint = MagicMock(name='torch.utils.checkpoint')
mock_torch_utils_pytree = MagicMock(name='torch.utils._pytree')
mock_torchvision = MagicMock(name='torchvision')
mock_torchvision.ops = MagicMock(name='torchvision.ops')
mock_torchvision.ops.roi_align = MagicMock(name='torchvision.ops.roi_align')
mock_torchvision.ops.misc = MagicMock(name='torchvision.ops.misc')
mock_torchvision.datasets = MagicMock(name='torchvision.datasets')
mock_torchvision.datasets.vision = MagicMock(name='torchvision.datasets.vision')
mock_torchvision.transforms = MagicMock(name='torchvision.transforms')
mock_torchvision.transforms.functional = MagicMock(name='torchvision.transforms.functional')
mock_torchvision.utils = MagicMock(name='torchvision.utils')
mock_insightface = MagicMock(name='insightface')
mock_insightface.app = MagicMock(name='insightface.app')
mock_timm = MagicMock(name='timm')
mock_timm.models = MagicMock(name='timm.models')
mock_timm.models.layers = MagicMock(name='timm.models.layers')
mock_pycocotools = MagicMock(name='pycocotools')
mock_pycocotools.mask = MagicMock(name='pycocotools.mask')
mock_psutil = MagicMock(name='psutil')
mock_psutil.cpu_percent.return_value = 50.0
mock_psutil.virtual_memory.return_value = MagicMock(percent=50.0, available=1024 * 1024 * 1024)
mock_psutil.disk_usage.return_value = MagicMock(percent=50.0)
mock_process = mock_psutil.Process.return_value
mock_process.memory_info.return_value.rss = 100 * 1024 * 1024
mock_process.cpu_percent.return_value = 10.0
mock_matplotlib = MagicMock(name='matplotlib')
mock_matplotlib.__path__ = ['fake']
mock_matplotlib.ticker = MagicMock(name='matplotlib.ticker')
mock_matplotlib.figure = MagicMock(name='matplotlib.figure')
mock_matplotlib.backends = MagicMock(name='matplotlib.backends')
mock_matplotlib.backends.backend_agg = MagicMock(name='matplotlib.backends.backend_agg')
modules_to_mock = {'torch': mock_torch, 'torch.hub': mock_torch.hub, 'torch.distributed': mock_torch.distributed, 'torch.multiprocessing': mock_torch.multiprocessing, 'torch.autograd': mock_torch_autograd, 'torch.nn': mock_torch_nn, 'torch.nn.attention': mock_torch_nn.attention, 'torch.nn.init': mock_torch_nn.init, 'torch.nn.functional': mock_torch_nn_functional, 'torch.optim': mock_torch_optim, 'torch.utils': mock_torch_utils, 'torch.utils.data': mock_torch_utils_data, 'torch.utils.checkpoint': mock_torch_utils_checkpoint, 'torch.utils._pytree': mock_torch_utils_pytree, 'torchvision': mock_torchvision, 'torchvision.ops': mock_torchvision.ops, 'torchvision.ops.roi_align': mock_torchvision.ops.roi_align, 'torchvision.ops.misc': mock_torchvision.ops.misc, 'torchvision.datasets': mock_torchvision.datasets, 'torchvision.datasets.vision': mock_torchvision.datasets.vision, 'torchvision.transforms': mock_torchvision.transforms, 'torchvision.transforms.functional': mock_torchvision.transforms.functional, 'torchvision.utils': mock_torchvision.utils, 'insightface': mock_insightface, 'insightface.app': mock_insightface.app, 'timm': mock_timm, 'timm.models': mock_timm.models, 'timm.models.layers': mock_timm.models.layers, 'onnxruntime': MagicMock(name='onnxruntime'), 'DAM4SAM': MagicMock(name='DAM4SAM'), 'DAM4SAM.utils': MagicMock(name='DAM4SAM.utils'), 'DAM4SAM.dam4sam_tracker': MagicMock(name='DAM4SAM.dam4sam_tracker'), 'GPUtil': MagicMock(getGPUs=lambda: [MagicMock(memoryUtil=0.5)]), 'pycocotools': mock_pycocotools, 'pycocotools.mask': mock_pycocotools.mask, 'psutil': mock_psutil, 'matplotlib': mock_matplotlib, 'matplotlib.ticker': mock_matplotlib.ticker, 'matplotlib.figure': mock_matplotlib.figure, 'matplotlib.backends': mock_matplotlib.backends, 'matplotlib.backends.backend_agg': mock_matplotlib.backends.backend_agg, 'matplotlib.pyplot': MagicMock(), 'scenedetect': MagicMock(), 'yt_dlp': MagicMock(), 'pyiqa': MagicMock(name='pyiqa'), 'mediapipe': MagicMock(), 'mediapipe.tasks': MagicMock(), 'mediapipe.tasks.python': MagicMock(), 'mediapipe.tasks.python.vision': MagicMock(), 'lpips': MagicMock(name='lpips'), 'numba': MagicMock(name='numba'), 'skimage': MagicMock(name='skimage'), 'skimage.metrics': MagicMock(name='skimage.metrics')}
mock_pydantic_settings = MagicMock(name='pydantic_settings')
mock_pydantic_settings.BaseSettings = pydantic.BaseModel
mock_pydantic_settings.SettingsConfigDict = dict
modules_to_mock['pydantic_settings'] = mock_pydantic_settings
@pytest.fixture
def mock_ui_state():
    """
    Provides a dictionary with default values for UI-related event models.
    """
    ...

@pytest.fixture
def sample_frames_data():
    ...

@pytest.fixture
def sample_scenes():
    ...

class TestUtils:
    @pytest.mark.parametrize('value, to_type, expected', [('True', bool, True), ('false', bool, False), ('1', bool, True), ('0', bool, False), ('yes', bool, True), ('no', bool, False), (True, bool, True), (False, bool, False), ('123', int, 123), (123, int, 123), ('123.45', float, 123.45), (123.45, float, 123.45), ('string', str, 'string')])
    def test_coerce(self, value, to_type, expected):
        ...
    def test_coerce_invalid_raises(self):
        ...
    def test_config_init(self):
        ...
    @patch('pathlib.Path.mkdir', MagicMock())
    @patch('pathlib.Path.touch', MagicMock())
    @patch('pathlib.Path.unlink', MagicMock())
    def test_validation_error(self):
        """
        Test that a validation error is raised for invalid config.
        """
        ...

class TestAppLogger:
    def test_app_logger_instantiation(self):
        """
        Tests that the logger can be instantiated with a valid config.
        """
        ...
    def test_auto_set_thresholds(self):
        ...
    def test_apply_all_filters_with_face_and_mask(self, sample_frames_data):
        """
        Verify filtering by face similarity and mask area.
        """
        ...
    def test_calculate_quality_metrics_with_niqe(self):
        """
        Test quality metrics calculation including NIQE.
        """
        ...

class TestPreAnalysisEvent:
    def test_face_ref_validation(self, tmp_path, mock_ui_state):
        """
        Test the custom validator for face_ref_img_path.
        """
        ...

```

### `ðŸ“„ tests/test_database.py`

```python
import pytest
import sqlite3
import json
from pathlib import Path
from core.database import Database

@pytest.fixture
def db_path(tmp_path):
    ...

@pytest.fixture
def db(db_path):
    ...

def test_create_tables(db, db_path):
    ...

def test_insert_metadata_and_flush(db):
    ...

def test_insert_metadata_batch_flush(db):
    ...

def test_clear_metadata(db):
    ...

def test_count_errors(db):
    ...

def test_migration_adds_column(tmp_path):
    ...

def test_metrics_json_parsing(db):
    ...

def test_mask_empty_conversion(db):
    ...

```

### `ðŸ“„ tests/test_dedup.py`

```python
import pytest
import numpy as np
import imagehash
import sys
from pathlib import Path
from unittest.mock import MagicMock, patch
from core.filtering import _apply_deduplication_filter, _run_batched_lpips
from core.config import Config
from core.managers import ThumbnailManager

modules_to_mock = {'sam3': MagicMock(), 'sam3.model_builder': MagicMock(), 'sam3.model.sam3_video_predictor': MagicMock(), 'mediapipe': MagicMock(), 'mediapipe.tasks': MagicMock(), 'mediapipe.tasks.python': MagicMock(), 'mediapipe.tasks.python.vision': MagicMock(), 'pyiqa': MagicMock(), 'scenedetect': MagicMock(), 'lpips': MagicMock(), 'yt_dlp': MagicMock(), 'numba': MagicMock(), 'matplotlib': MagicMock(), 'matplotlib.pyplot': MagicMock(), 'matplotlib.ticker': MagicMock(), 'torch': MagicMock(), 'torchvision': MagicMock(), 'torchvision.ops': MagicMock(), 'torchvision.transforms': MagicMock(), 'insightface': MagicMock(), 'insightface.app': MagicMock()}
patcher = patch.dict(sys.modules, modules_to_mock)
@pytest.fixture
def mock_thumbnail_manager():
    ...

@pytest.fixture
def sample_frames_for_dedup():
    ...

def test_dedup_phash_replacement(sample_frames_for_dedup, mock_thumbnail_manager):
    ...

def test_dedup_phash_no_replacement(sample_frames_for_dedup, mock_thumbnail_manager):
    ...

def test_dedup_disabled(sample_frames_for_dedup, mock_thumbnail_manager):
    ...

def test_dedup_threshold(sample_frames_for_dedup, mock_thumbnail_manager):
    ...

def test_run_batched_lpips(mock_thumbnail_manager):
    ...

```

### `ðŸ“„ tests/test_export.py`

```python
import pytest
from unittest.mock import MagicMock, patch
import sys
from pathlib import Path
import json
from core.events import ExportEvent
from core.export import export_kept_frames

@pytest.fixture
def mock_config():
    ...

@pytest.fixture
def mock_logger():
    ...

@patch('subprocess.Popen')
@patch('core.export.apply_all_filters_vectorized')
def test_export_kept_frames(mock_filter, mock_popen, mock_config, mock_logger, tmp_path):
    ...

```

### `ðŸ“„ tests/test_gallery_utils.py`

```python
import pytest
from unittest.mock import MagicMock
from ui.gallery_utils import scene_caption, create_scene_thumbnail_with_badge
from core.models import Scene
import numpy as np

def test_scene_caption_dict():
    ...

def test_scene_caption_obj():
    ...

def test_create_scene_thumbnail_with_badge():
    ...

def test_create_scene_thumbnail_included():
    ...

```

### `ðŸ“„ tests/test_managers.py`

```python
import pytest
from unittest.mock import MagicMock, patch, ANY
from pathlib import Path
import numpy as np
from core.managers import ThumbnailManager, ModelRegistry, VideoManager
from PIL import Image

class TestThumbnailManager:
    @pytest.fixture
    def manager(self, mock_logger, mock_config, tmp_path):
        ...
    @patch('PIL.Image.open')
    def test_get_existing(self, mock_open_img, manager, tmp_path):
        ...
    def test_get_missing(self, manager, tmp_path):
        ...
    def test_clear_cache(self, manager):
        ...
    @patch('PIL.Image.open')
    def test_cleanup_old_entries(self, mock_open_img, manager, tmp_path):
        ...

class TestModelRegistry:
    @pytest.fixture
    def registry(self, mock_logger):
        ...
    def test_get_or_load(self, registry):
        ...
    def test_clear(self, registry):
        ...

class TestVideoManager:
    @patch('cv2.VideoCapture')
    def test_get_video_info(self, mock_cap_cls):
        ...
    @patch('cv2.VideoCapture')
    def test_get_video_info_fail(self, mock_cap_cls):
        ...
    @patch('core.managers.validate_video_file')
    def test_prepare_video(self, mock_validate, mock_config):
        ...

```

### `ðŸ“„ tests/test_pipelines.py`

```python
import pytest
from unittest.mock import MagicMock, patch, ANY, mock_open
import sys
from pathlib import Path
from queue import Queue
import threading
import json
import numpy as np
from core.config import Config
from core.models import AnalysisParameters, Scene
from core.pipelines import ExtractionPipeline, AnalysisPipeline, run_ffmpeg_extraction

@pytest.fixture
def mock_config(tmp_path):
    ...

@pytest.fixture
def mock_logger():
    ...

@pytest.fixture
def mock_params():
    ...

@pytest.fixture
def mock_progress_queue():
    ...

@pytest.fixture
def mock_cancel_event():
    ...

@pytest.fixture
def mock_thumbnail_manager():
    ...

@pytest.fixture
def mock_model_registry():
    ...

class TestExtractionPipeline:
    @patch('core.pipelines.run_ffmpeg_extraction')
    @patch('core.pipelines.VideoManager')
    def test_extraction_video_success(self, mock_vm_cls, mock_ffmpeg, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event):
        ...
    @patch('core.pipelines.run_ffmpeg_extraction')
    @patch('core.pipelines.VideoManager')
    def test_extraction_video_cancel(self, mock_vm_cls, mock_ffmpeg, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event):
        ...
    @patch('core.utils.is_image_folder', return_value=True)
    @patch('core.utils.list_images')
    @patch('core.pipelines.make_photo_thumbs')
    def test_extraction_folder(self, mock_thumbs, mock_list_imgs, mock_is_folder, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event):
        ...
    @patch('subprocess.Popen')
    def test_run_ffmpeg_extraction(self, mock_popen, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event, tmp_path):
        ...

class TestAnalysisPipeline:
    @patch('core.pipelines.SubjectMasker')
    @patch('core.pipelines.initialize_analysis_models')
    @patch('core.pipelines.Database')
    def test_run_full_analysis_success(self, mock_db_cls, mock_init_models, mock_masker_cls, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event, mock_thumbnail_manager, mock_model_registry):
        ...
    @patch('core.pipelines.SubjectMasker')
    @patch('core.pipelines.initialize_analysis_models')
    def test_run_full_analysis_cancel(self, mock_init_models, mock_masker_cls, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event, mock_thumbnail_manager, mock_model_registry):
        ...
    @patch('core.pipelines.initialize_analysis_models')
    @patch('core.pipelines.Database')
    def test_run_analysis_only(self, mock_db_cls, mock_init_models, mock_config, mock_logger, mock_params, mock_progress_queue, mock_cancel_event, mock_thumbnail_manager, mock_model_registry):
        ...

class TestSessionLoad:
    @patch('core.pipelines.validate_session_dir')
    def test_execute_session_load_success(self, mock_validate, mock_logger, tmp_path):
        ...
    @patch('core.pipelines.validate_session_dir')
    def test_execute_session_load_fail_validate(self, mock_validate, mock_logger):
        ...

```

### `ðŸ“„ tests/test_progress.py`

```python
import pytest
from unittest.mock import MagicMock
from queue import Queue
from core.progress import AdvancedProgressTracker

def test_progress_tracker():
    ...

```

### `ðŸ“„ tests/test_scene_utils.py`

```python
import pytest
from unittest.mock import MagicMock, patch, ANY, mock_open
import sys
from pathlib import Path
from queue import Queue
import threading
import json
import numpy as np
import torch
from core.config import Config
from core.models import AnalysisParameters, Scene
from core.scene_utils import SeedSelector, MaskPropagator, SubjectMasker, run_scene_detection

@pytest.fixture
def mock_config(tmp_path):
    ...

@pytest.fixture
def mock_logger():
    ...

@pytest.fixture
def mock_params():
    ...

class TestSeedSelector:
    def test_select_seed_largest_person(self, mock_config, mock_logger, mock_params):
        ...
    def test_select_seed_text_prompt(self, mock_config, mock_logger, mock_params):
        ...

class TestMaskPropagator:
    @patch('core.scene_utils.mask_propagator.postprocess_mask', side_effect=lambda x, **k: x)
    def test_propagate_success(self, mock_post, mock_config, mock_logger, mock_params):
        ...

class TestSubjectMasker:
    @patch('core.scene_utils.subject_masker.create_frame_map', return_value={0: 'frame_0.png'})
    def test_run_propagation(self, mock_create_map, mock_config, mock_logger, mock_params, tmp_path):
        ...

```

### `ðŸ“„ tests/test_ui.py`

```python
import asyncio
from playwright.async_api import async_playwright

async def main():
    ...

```

### `ðŸ“„ tests/test_ui_unit.py`

```python
import pytest
from unittest.mock import MagicMock, patch, ANY
import gradio as gr
from ui.app_ui import AppUI
from core.events import ExtractionEvent
from core.pipelines import execute_extraction

@pytest.fixture
def app_ui(mock_config, mock_logger, mock_progress_queue, mock_cancel_event, mock_thumbnail_manager, mock_model_registry):
    ...

def test_stepper_html(app_ui):
    ...

def test_run_extraction_wrapper(app_ui):
    ...

def test_fix_strategy_visibility_face_ref(app_ui):
    ...

def test_fix_strategy_visibility_text(app_ui):
    ...

def test_get_metric_description(app_ui):
    ...

```

### `ðŸ“„ ui/app_ui.py`

```python
from __future__ import annotations
import threading
import time
import sys
import re
from pathlib import Path
from queue import Queue, Empty
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, List, Dict, Any, Callable, Deque, Generator
from collections import deque
import gradio as gr
import torch
import numpy as np
import cv2
import uuid
import shutil
from core.config import Config
from core.logger import AppLogger
from core.managers import ThumbnailManager, ModelRegistry
from core.models import Scene, SceneState, AnalysisParameters
from core.utils import is_image_folder
from core.scene_utils import toggle_scene_status, save_scene_seeds, _recompute_single_preview, _create_analysis_context, _wire_recompute_handler, get_scene_status_text
from core.pipelines import execute_extraction, execute_pre_analysis, execute_propagation, execute_analysis, execute_session_load, AdvancedProgressTracker
from core.export import export_kept_frames, dry_run_export
from ui.gallery_utils import build_scene_gallery_items, on_filters_changed, auto_set_thresholds, _update_gallery, scene_caption, create_scene_thumbnail_with_badge
from core.events import ExtractionEvent, PreAnalysisEvent, PropagationEvent, SessionLoadEvent, FilterEvent, ExportEvent
from core.batch_manager import BatchManager, BatchStatus, BatchItem

class AppUI:
    """
    Main UI class for the Frame Extractor & Analyzer application.

    Manages the Gradio interface, event handlers, and interaction with backend pipelines.
    """
    def __init__(self, config: 'Config', logger: 'AppLogger', progress_queue: Queue, cancel_event: threading.Event, thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'):
        """
        Initialize the AppUI.

        Args:
        config: Application configuration.
        logger: Application logger.
        progress_queue: Queue for progress updates.
        cancel_event: Event to signal task cancellation.
        thumbnail_manager: Manager for thumbnail caching.
        model_registry: Registry for ML models.
        """
        ...
    def preload_models(self):
        """
        Asynchronously preloads heavy models (SAM3) in a background thread.
        """
        ...
    def _get_stepper_html(self, current_step: int=0) -> str:
        """
        Generates the HTML for the workflow progress stepper.

        Args:
        current_step: The index of the current active step (0-based).

        Returns:
        HTML string for the stepper component.
        """
        ...
    def build_ui(self) -> gr.Blocks:
        """
        Constructs the entire Gradio UI layout.

        Returns:
        The Gradio Blocks instance containing the application UI.
        """
        ...
    def _get_comp(self, name: str) -> Optional[gr.components.Component]:
        """
        Retrieves a component by name from the internal registry.
        """
        ...
    def _reg(self, key: str, component: gr.components.Component) -> gr.components.Component:
        """
        Registers a component for later retrieval by UI mapping key.
        """
        ...
    def _create_component(self, name: str, comp_type: str, kwargs: dict) -> gr.components.Component:
        """
        Helper to create and register a Gradio component.

        Args:
        name: Unique name for the component.
        comp_type: String identifier for the component type (e.g., 'button', 'textbox').
        kwargs: Arguments to pass to the component constructor.

        Returns:
        The created Gradio component.
        """
        ...
    def _build_header(self):
        """
        Builds the UI header section with title and status indicators.
        """
        ...
    def _build_main_tabs(self):
        """
        Constructs the main tabbed interface.
        """
        ...
    def _build_footer(self):
        """
        Builds the footer with status bar, logs, and help section.
        """
        ...
    def _create_extraction_tab(self):
        """
        Creates the content for the 'Source' tab.
        """
        ...
    def _create_define_subject_tab(self):
        """
        Creates the content for the 'Subject' tab.
        """
        ...
    def _create_scene_selection_tab(self):
        """
        Creates the content for the 'Scenes' tab.
        """
        ...
    def _create_metrics_tab(self):
        """
        Creates the content for the 'Metrics' tab.
        """
        ...
    def _create_filtering_tab(self):
        """
        Creates the content for the 'Export' tab.
        """
        ...
    def get_all_filter_keys(self) -> list[str]:
        """
        Returns a list of all available filter metric keys.
        """
        ...
    def get_metric_description(self, metric_name: str) -> str:
        """
        Returns a user-friendly description for a given metric.
        """
        ...
    def _create_event_handlers(self):
        """
        Sets up all global event listeners and state management.
        """
        ...
    def update_stepper(self, evt: gr.SelectData):
        """
        Updates the stepper HTML when a tab is selected.
        """
        ...
    def _push_history(self, scenes: List[Dict], history: Deque) -> Deque:
        """
        Pushes the current scene state to the history stack for undo support.
        """
        ...
    def _undo_last_action(self, scenes: List[Dict], history: Deque, output_dir: str, view: str) -> tuple:
        """
        Reverts the last action by popping from the history stack.
        """
        ...
    def _run_task_with_progress(self, task_func: Callable, output_components: list, progress: Callable, *args) -> Generator[dict, None, None]:
        """
        Executes a background task while streaming progress updates to the UI.

        Args:
        task_func: The function to execute.
        output_components: List of components to update (deprecated).
        progress: Gradio progress callback.
        args: Arguments for the task function.

        Yields:
        Dictionary of UI updates.
        """
        ...
    def on_select_yolo_subject_wrapper(self, subject_id: str, scenes: list, shot_id: int, outdir: str, view: str, history: Deque, *ana_args) -> tuple:
        """
        Wrapper for handling subject selection from the discovery gallery.

        Updates the selected subject for a scene and recomputes the preview.
        """
        ...
    def _setup_bulk_scene_handlers(self):
        """
        Configures event handlers for the scene selection tab (pagination, bulk actions).
        """
        ...
    def on_reset_scene_wrapper(self, scenes, shot_id, outdir, view, history, *ana_args):
        """
        Resets a scene's manual overrides to its initial state.
        """
        ...
    def on_select_for_edit(self, scenes, view, indexmap, outputdir, yoloresultsstate, event: Optional[gr.EventData]=None):
        """
        Handles selection of a scene from the gallery for editing.
        """
        ...
    def on_editor_toggle(self, scenes, selected_shotid, outputfolder, view, new_status, history):
        """
        Toggles the included/excluded status of a scene.
        """
        ...
    def _toggle_pause(self, tracker: 'AdvancedProgressTracker') -> str:
        """
        Toggles the pause state of the current running task.
        """
        ...
    def run_system_diagnostics(self) -> Generator[str, None, None]:
        """
        Runs a comprehensive suite of system checks and a dry run.
        """
        ...
    def _create_pre_analysis_event(self, *args: Any) -> 'PreAnalysisEvent':
        """
        Helper to construct a PreAnalysisEvent from UI arguments.
        """
        ...
    def _run_pipeline(self, pipeline_func: Callable, event: Any, progress: Callable, success_callback: Optional[Callable]=None, *args):
        """
        Generic wrapper to run a pipeline function and handle progress/errors.

        Args:
        pipeline_func: The pipeline generator function to run.
        event: The event object to pass to the pipeline.
        progress: Gradio progress callback.
        success_callback: Optional callback to run on successful completion.
        """
        ...
    def run_extraction_wrapper(self, *args, progress=None):
        """
        Wrapper to execute the extraction pipeline.
        """
        ...
    def add_to_queue_handler(self, *args):
        """
        Adds a job to the batch processing queue.
        """
        ...
    def clear_queue_handler(self):
        """
        Clears all items from the batch queue.
        """
        ...
    def _batch_processor(self, item: BatchItem, progress_callback: Callable):
        """
        Callback to process a single item in the batch queue.
        """
        ...
    def start_batch_wrapper(self, workers: float):
        """
        Starts processing the batch queue with specified number of workers.
        """
        ...
    def stop_batch_handler(self):
        """
        Stops the batch processing.
        """
        ...
    def _on_extraction_success(self, result: dict) -> dict:
        """
        Callback for successful extraction.
        """
        ...
    def _on_pre_analysis_success(self, result: dict) -> dict:
        """
        Callback for successful pre-analysis.
        """
        ...
    def run_pre_analysis_wrapper(self, *args, progress=None):
        """
        Wrapper to execute the pre-analysis pipeline.
        """
        ...
    def run_propagation_wrapper(self, scenes, *args, progress=None):
        """
        Wrapper to execute the mask propagation pipeline.
        """
        ...
    def _on_propagation_success(self, result: dict) -> dict:
        """
        Callback for successful propagation.
        """
        ...
    def run_analysis_wrapper(self, scenes, *args, progress=None):
        """
        Wrapper to execute the full analysis pipeline.
        """
        ...
    def _on_analysis_success(self, result: dict) -> dict:
        """
        Callback for successful analysis.
        """
        ...
    def run_session_load_wrapper(self, session_path: str):
        """
        Loads a previous session and updates the UI state.
        """
        ...
    def _fix_strategy_visibility(self, strategy: str) -> dict:
        """
        Adjusts UI component visibility based on the selected seed strategy.
        """
        ...
    def _setup_visibility_toggles(self):
        """
        Configures dynamic visibility logic for UI components.
        """
        ...
    def get_inputs(self, keys: list[str]) -> list[gr.components.Component]:
        """
        Retrieves a list of UI components based on their registry keys.
        """
        ...
    def _setup_pipeline_handlers(self):
        """
        Configures event handlers for starting main processing pipelines.
        """
        ...
    def on_identity_confidence_change(self, confidence: float, all_faces: list) -> gr.update:
        """
        Updates the face discovery gallery based on clustering confidence.
        """
        ...
    def on_discovered_face_select(self, all_faces: list, confidence: float, *args, evt: gr.EventData=None) -> tuple[str, Optional[np.ndarray]]:
        """
        Handles selection of a face cluster from the discovery gallery.
        """
        ...
    def on_find_people_from_video(self, *args) -> tuple[gr.update, list, float, list]:
        """
        Scans the video for faces to populate the discovery gallery.
        """
        ...
    def on_apply_bulk_scene_filters_extended(self, scenes: list, min_mask_area: float, min_face_sim: float, min_confidence: float, enable_face_filter: bool, output_folder: str, view: str) -> tuple:
        """
        Applies filters to all scenes and updates their status.
        """
        ...
    def _get_smart_mode_updates(self, is_enabled: bool) -> list[gr.update]:
        """
        Calculates slider updates when toggling 'Smart Mode'.
        """
        ...
    def _setup_filtering_handlers(self):
        """
        Configures event handlers for the filtering and export tab.
        """
        ...
    def on_preset_changed(self, preset_name: str) -> list[Any]:
        """
        Updates filter sliders when a preset is selected.
        """
        ...
    def on_filters_changed_wrapper(self, all_frames_data: list, per_metric_values: dict, output_dir: str, gallery_view: str, show_overlay: bool, overlay_alpha: float, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, smart_mode_enabled: bool, *slider_values: float) -> tuple[str, gr.update]:
        """
        Updates the results gallery when filters change.

        Handles smart mode percentile conversion if enabled.
        """
        ...
    def calculate_visual_diff(self, gallery: gr.Gallery, all_frames_data: list, dedup_method_ui: str, dedup_thresh: int, ssim_thresh: float, lpips_thresh: float) -> Optional[np.ndarray]:
        """
        Computes a side-by-side comparison image for duplicate inspection.
        """
        ...
    def on_reset_filters(self, all_frames_data: list, per_metric_values: dict, output_dir: str) -> tuple:
        """
        Resets all filter settings to their defaults.
        """
        ...
    def on_auto_set_thresholds(self, per_metric_values: dict, p: int, *checkbox_values: bool) -> list[gr.update]:
        """
        Automatically sets filter thresholds based on data percentiles.
        """
        ...
    def export_kept_frames_wrapper(self, all_frames_data: list, output_dir: str, video_path: str, enable_crop: bool, crop_ars: str, crop_padding: int, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> str:
        """
        Wrapper to execute the final frame export.
        """
        ...
    def dry_run_export_wrapper(self, all_frames_data: list, output_dir: str, video_path: str, enable_crop: bool, crop_ars: str, crop_padding: int, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> str:
        """
        Wrapper to perform a dry run of the export.
        """
        ...

```

### `ðŸ“„ ui/gallery_utils.py`

```python
from __future__ import annotations
import math
import cv2
import numpy as np
import json
from pathlib import Path
from typing import Optional, List, Dict, Tuple, Any, Union
import gradio as gr
from collections import Counter
from core.models import Scene
from core.filtering import apply_all_filters_vectorized
from core.utils import render_mask_overlay
from core.events import FilterEvent
from core.shared import scene_matches_view, create_scene_thumbnail_with_badge, scene_caption, build_scene_gallery_items

def _update_gallery(all_frames_data: list[dict], filters: dict, output_dir: str, gallery_view: str, show_overlay: bool, overlay_alpha: float, thumbnail_manager: Any, config: Any, logger: Any) -> tuple[str, gr.update]:
    """
    Updates the Gradio gallery based on applied filters.

    Returns:
    A tuple containing the status text and a Gradio update object for the gallery.
    """
    ...

def on_filters_changed(event: FilterEvent, thumbnail_manager: Any, config: Any, logger: Any) -> dict:
    """
    Event handler for when filter settings are modified.

    Re-filters data and updates the gallery view.
    """
    ...

def auto_set_thresholds(per_metric_values: dict, p: int, slider_keys: list[str], selected_metrics: list[str]) -> dict:
    """
    Calculates threshold values based on data percentiles.

    Args:
    per_metric_values: Dictionary of metric values.
    p: Percentile value.
    slider_keys: List of slider component keys.
    selected_metrics: List of metrics to auto-tune.

    Returns:
    Dictionary of updates for the sliders.
    """
    ...

```

### `ðŸ“„ ui/handlers/__init__.py`

```python
"""
UI Handlers package for Frame Extractor.

This package contains handler modules that encapsulate related UI functionality,
extracted from the monolithic AppUI class to improve maintainability.
"""

from __future__ import annotations
from ui.handlers.extraction_handler import ExtractionHandler
from ui.handlers.analysis_handler import AnalysisHandler
from ui.handlers.filtering_handler import FilteringHandler

__all__ = ['ExtractionHandler', 'AnalysisHandler', 'FilteringHandler']
```

### `ðŸ“„ ui/handlers/analysis_handler.py`

```python
"""
Analysis handler for Frame Extractor UI.

This module contains handlers related to the analysis pipelines,
including pre-analysis, propagation, and full analysis.
"""

from __future__ import annotations
from typing import TYPE_CHECKING, Callable, Optional, Any, Generator, List
import gradio as gr

class AnalysisHandler:
    """
    Handles analysis-related UI operations.

    Extracted from AppUI to reduce class size and improve maintainability.
    """
    def __init__(self, app: 'AppUI', config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'):
        """
        Initialize AnalysisHandler.

        Args:
        app: Parent AppUI instance
        config: Application configuration
        logger: Application logger
        thumbnail_manager: Thumbnail cache manager
        model_registry: Model registry
        """
        ...
    def run_pre_analysis(self, progress: Callable, *args) -> Generator[dict, None, None]:
        """
        Run the pre-analysis pipeline.

        Args:
        progress: Gradio progress callback
        *args: UI component values

        Yields:
        Progress updates and final results
        """
        ...
    def on_pre_analysis_success(self, result: dict) -> dict:
        """
        Handle successful pre-analysis completion.

        Args:
        result: Result dictionary from pre-analysis

        Returns:
        Dictionary of component updates
        """
        ...
    def run_propagation(self, scenes: list, progress: Callable, *args) -> Generator[dict, None, None]:
        """
        Run the mask propagation pipeline.

        Args:
        scenes: List of scenes to process
        progress: Gradio progress callback
        *args: UI component values

        Yields:
        Progress updates and final results
        """
        ...
    def on_propagation_success(self, result: dict) -> dict:
        """
        Handle successful propagation completion.

        Args:
        result: Result dictionary from propagation

        Returns:
        Dictionary of component updates
        """
        ...
    def run_analysis(self, scenes: list, progress: Callable, *args) -> Generator[dict, None, None]:
        """
        Run the full analysis pipeline.

        Args:
        scenes: List of scenes to process
        progress: Gradio progress callback
        *args: UI component values

        Yields:
        Progress updates and final results
        """
        ...
    def on_analysis_success(self, result: dict) -> dict:
        """
        Handle successful analysis completion.

        Args:
        result: Result dictionary from analysis

        Returns:
        Dictionary of component updates
        """
        ...

```

### `ðŸ“„ ui/handlers/extraction_handler.py`

```python
"""
Extraction handler for Frame Extractor UI.

This module contains handlers related to the extraction pipeline,
including video extraction, session loading, and batch processing.
"""

from __future__ import annotations
from typing import TYPE_CHECKING, Callable, Optional, Any, Generator
import gradio as gr

class ExtractionHandler:
    """
    Handles extraction-related UI operations.

    Extracted from AppUI to reduce class size and improve maintainability.
    """
    def __init__(self, app: 'AppUI', config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'):
        """
        Initialize ExtractionHandler.

        Args:
        app: Parent AppUI instance
        config: Application configuration
        logger: Application logger
        thumbnail_manager: Thumbnail cache manager
        model_registry: Model registry
        """
        ...
    def run_extraction(self, progress: Callable, *args) -> Generator[dict, None, None]:
        """
        Run the extraction pipeline.

        Args:
        progress: Gradio progress callback
        *args: UI component values

        Yields:
        Progress updates and final results
        """
        ...
    def on_extraction_success(self, result: dict) -> dict:
        """
        Handle successful extraction completion.

        Args:
        result: Result dictionary from extraction

        Returns:
        Dictionary of component updates
        """
        ...
    def run_session_load(self, session_path: str) -> Generator[dict, None, None]:
        """
        Load a previous session.

        Args:
        session_path: Path to session directory

        Yields:
        Progress updates and component updates
        """
        ...

```

### `ðŸ“„ ui/handlers/filtering_handler.py`

```python
"""
Filtering handler for Frame Extractor UI.

This module contains handlers related to frame filtering and export.
"""

from __future__ import annotations
from typing import TYPE_CHECKING, Callable, Optional, Any, Dict, List
import gradio as gr

class FilteringHandler:
    """
    Handles filtering-related UI operations.

    Extracted from AppUI to reduce class size and improve maintainability.
    """
    def __init__(self, app: 'AppUI', config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager'):
        """
        Initialize FilteringHandler.

        Args:
        app: Parent AppUI instance
        config: Application configuration
        logger: Application logger
        thumbnail_manager: Thumbnail cache manager
        """
        ...
    def on_filters_changed(self, all_frames_data: list, per_metric_values: dict, output_dir: str, gallery_view: str, show_overlay: bool, overlay_alpha: float, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, smart_mode_enabled: bool, *slider_values: float) -> dict:
        """
        Handle filter changes and update gallery.

        Args:
        all_frames_data: All frame metadata
        per_metric_values: Per-metric value distributions
        output_dir: Output directory path
        gallery_view: Current gallery view mode
        show_overlay: Whether to show mask overlay
        overlay_alpha: Overlay transparency
        require_face_match: Whether face matching is required
        dedup_thresh: Deduplication threshold
        dedup_method_ui: Deduplication method
        smart_mode_enabled: Whether smart mode is enabled
        *slider_values: Slider values for each metric

        Returns:
        Dictionary of component updates
        """
        ...
    def on_preset_changed(self, preset_name: str) -> dict:
        """
        Handle preset selection.

        Args:
        preset_name: Name of the selected preset

        Returns:
        Dictionary of slider updates
        """
        ...
    def on_reset_filters(self, all_frames_data: list, per_metric_values: dict, output_dir: str) -> dict:
        """
        Reset all filters to default values.

        Args:
        all_frames_data: All frame metadata
        per_metric_values: Per-metric value distributions
        output_dir: Output directory path

        Returns:
        Dictionary of component updates
        """
        ...
    def on_auto_set_thresholds(self, per_metric_values: dict, percentile: int, *checkbox_values: bool) -> dict:
        """
        Automatically set thresholds based on percentiles.

        Args:
        per_metric_values: Per-metric value distributions
        percentile: Percentile to use for threshold
        *checkbox_values: Which metrics are enabled

        Returns:
        Dictionary of slider updates
        """
        ...

```


## 5. Development Workflows

### Bug Fix Workflow
1. **Reproduce**: Create a test case in `tests/test_reproduce_issue.py`.
2. **Log**: Use `logger.debug()` to trace execution.
3. **Fix**: Implement fix in `core/` or `ui/`.
4. **Verify**: Run `python -m pytest tests/`.
5. **Clean**: Remove temporary test files.

### Adding a New Metric
1. **Config**: Add default thresholds to `Config` in `core/config.py`.
2. **Extraction**: Update `_extract_metric_arrays()` in `core/filtering.py`.
3. **UI**: Add slider in `ui/app_ui.py` inside `_create_filtering_tab`.
4. **Analysis**: Update `calculate_quality_metrics` in `core/models.py`.


## 6. Testing & Mocking Guide

### When to Mock
- **File I/O**: Patch `pathlib.Path.exists`, `open`.
- **ML Models**: Always mock `SAM3Wrapper`, `FaceAnalysis`, `FaceLandmarker`.
- **Submodules**: Mock `sam3` package to avoid import errors.

### Common Patterns
```python
# Mocking a class method
@patch("core.managers.ModelRegistry.get_tracker")
def test_tracker(mock_get, app_ui):
    mock_get.return_value = MagicMock()
    ...
```

### E2E vs Unit
- **Unit**: Fast, mocks everything. Run pre-commit.
- **E2E**: Slower, uses `mock_app.py` to simulate backend. Checks UI flows.


## 7. Configuration Reference

See `core/config.py` for full list.

| Category | Key Fields | Default |
|----------|------------|---------|
| **Paths** | `logs_dir`, `models_dir`, `downloads_dir` | `logs`, `models`, `downloads` |
| **Models** | `face_model_name`, `tracker_model_name` | `buffalo_l`, `sam3` |
| **perf** | `analysis_default_workers` | 4 |
| **UI** | `default_thumb_megapixels` | 0.5 |


## 8. Troubleshooting

### Error: "CUDA out of memory"
- **Where**: SAM3 initialization, NIQE metric.
- **Fix**: Set `model_registry.runtime_device_override = 'cpu'`.
- **Prevention**: Call `cleanup_models()` between sessions.

### Error: "ModuleNotFoundError: sam3"
- **Cause**: Submodule not initialized.
- **Fix**: `git submodule update --init --recursive`.
- **Check**: Verify `SAM3_repo/` exists and has files.

### Error: "ValueError: ... is not in list" (Gradio)
- **Cause**: `gr.Radio` or `gr.Dropdown` value updated to something not in `choices`.
- **Fix**: Update `choices` list *before* setting `value`.


## 9. Performance & Memory

- **SAM3**: Requires ~8GB VRAM. Falls back to CPU (slow).
- **Thumbnails**: Cached in RAM (`ThumbnailManager`). LRU eviction.
- **Batch Processing**: Uses `ThreadPoolExecutor`. Limit workers in Config if OOM occurs.


## 10. API Quick Reference

### Key Functions
- `execute_extraction(event: ExtractionEvent) -> Generator`
- `execute_pre_analysis(event: PreAnalysisEvent) -> Generator`
- `execute_propagation(event: PropagationEvent) -> Generator`

### Event Models
- `ExtractionEvent`: Source path, method (interval/scene).
- `PreAnalysisEvent`: Analysis params, seed strategy.
- `PropagationEvent`: List of scenes to process.


## 11. Git & Deployment

- **Submodules**: Always update recursive.
- **Requirements**: `requirements.txt` is root.
- **Validation**: Verify model downloads with SHA256.


## 12. Contribution Guidelines

### Code Style
- **Formatting**: Use `black` formatter with default settings
- **Imports**: Sort with `isort`, group: stdlib â†’ third-party â†’ local
- **Naming**: snake_case for functions/variables, PascalCase for classes
- **Line Length**: 100 characters max
- **Docstrings**: Use Google-style docstrings for public APIs

### Pull Request Process
1. Create feature branch from `main`
2. Run `python -m pytest tests/` before committing
3. Update AGENTS.md if adding new modules: `python scripts/update_agents_md.py`
4. Request review from maintainers

### Adding New Modules
- Place business logic in `core/`
- Place UI components in `ui/`
- Update imports in `__init__.py` files
- Add test fixtures to `tests/conftest.py`


## 13. Security Considerations

### Model Downloads
- All model downloads are verified via SHA256 hash
- Never disable hash verification in production
- Use `core/utils.download_model()` which has built-in retry and validation

### User Inputs
- Video paths are validated via `validate_video_file()`
- Text prompts are sanitized before use with external models
- File exports use `sanitize_filename()` to prevent path traversal
- Never construct paths from user input without validation

### Session Data
- Session directories are validated before loading (`validate_session_dir()`)
- JSON files are parsed with error handling to prevent injection
