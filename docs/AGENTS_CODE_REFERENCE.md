---
description: Auto-generated code skeletons for the main application.
---

# Code Skeleton Reference

> **âš ï¸ AUTO-GENERATED FILE**: This file is generated by `scripts/update_agents_md.py`.
> Do not edit manually. Run `python scripts/update_agents_md.py` to regenerate.

This file contains auto-generated code skeletons for the main application.
For test references, see [tests/TESTS_CODE_REFERENCE.md](tests/TESTS_CODE_REFERENCE.md).
For developer guidelines, see [AGENTS.md](AGENTS.md).

## Project Structure

```text
.
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ changelog.md
â”œâ”€â”€ core
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ batch_manager.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ error_handling.py
â”‚   â”œâ”€â”€ events.py
â”‚   â”œâ”€â”€ export.py
â”‚   â”œâ”€â”€ filtering.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ managers.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ progress.py
â”‚   â”œâ”€â”€ sam3_patches.py
â”‚   â”œâ”€â”€ scene_utils
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ detection.py
â”‚   â”‚   â”œâ”€â”€ helpers.py
â”‚   â”‚   â”œâ”€â”€ mask_propagator.py
â”‚   â”‚   â”œâ”€â”€ seed_selector.py
â”‚   â”‚   â””â”€â”€ subject_masker.py
â”‚   â”œâ”€â”€ shared.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ jules_setup_script.sh
â”‚   â”œâ”€â”€ linux_run_app.sh
â”‚   â”œâ”€â”€ run_ux_audit.py
â”‚   â”œâ”€â”€ take_screenshot.py
â”‚   â”œâ”€â”€ update_agents_md.py
â”‚   â”œâ”€â”€ verification
â”‚   â”‚   â”œâ”€â”€ e2e_run.py
â”‚   â”‚   â””â”€â”€ verify_simple.py
â”‚   â””â”€â”€ verify_quality.py
â”œâ”€â”€ subject_frame_extractor.egg-info
â”‚   â”œâ”€â”€ SOURCES.txt
â”‚   â”œâ”€â”€ dependency_links.txt
â”‚   â”œâ”€â”€ requires.txt
â”‚   â””â”€â”€ top_level.txt
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ TESTING.md
â”‚   â”œâ”€â”€ TESTS_CODE_REFERENCE.md
â”‚   â”œâ”€â”€ assets
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ integration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ e2e_output_debug
â”‚   â”‚   â”‚   â”œâ”€â”€ frame_map.json
â”‚   â”‚   â”‚   â”œâ”€â”€ mask_metadata.json
â”‚   â”‚   â”‚   â”œâ”€â”€ masks
â”‚   â”‚   â”‚   â”œâ”€â”€ previews
â”‚   â”‚   â”‚   â”œâ”€â”€ progress.json
â”‚   â”‚   â”‚   â”œâ”€â”€ run_config.json
â”‚   â”‚   â”‚   â”œâ”€â”€ scene_seeds.json
â”‚   â”‚   â”‚   â”œâ”€â”€ scenes.json
â”‚   â”‚   â”‚   â””â”€â”€ thumbs
â”‚   â”‚   â””â”€â”€ test_real_workflow.py
â”‚   â”œâ”€â”€ mock_app.py
â”‚   â”œâ”€â”€ smoke_test_ui_init.py
â”‚   â”œâ”€â”€ ui
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ai_ux_analyzer.py
â”‚   â”‚   â”œâ”€â”€ conftest.py
â”‚   â”‚   â”œâ”€â”€ test_accessibility.py
â”‚   â”‚   â”œâ”€â”€ test_advanced_workflow.py
â”‚   â”‚   â”œâ”€â”€ test_ai_ux_audit.py
â”‚   â”‚   â”œâ”€â”€ test_app_flow.py
â”‚   â”‚   â”œâ”€â”€ test_bug_regression.py
â”‚   â”‚   â”œâ”€â”€ test_component_verification.py
â”‚   â”‚   â”œâ”€â”€ test_export_flow.py
â”‚   â”‚   â”œâ”€â”€ test_filters_real.py
â”‚   â”‚   â”œâ”€â”€ test_full_workflow_mocked.py
â”‚   â”‚   â”œâ”€â”€ test_session_lifecycle.py
â”‚   â”‚   â”œâ”€â”€ test_ui_interactions.py
â”‚   â”‚   â”œâ”€â”€ test_visual_regression.py
â”‚   â”‚   â”œâ”€â”€ test_with_sample_data.py
â”‚   â”‚   â””â”€â”€ visual_test_utils.py
â”‚   â””â”€â”€ unit
â”‚       â”œâ”€â”€ test_app_ui_logic.py
â”‚       â”œâ”€â”€ test_batch_manager.py
â”‚       â”œâ”€â”€ test_bug_fixes.py
â”‚       â”œâ”€â”€ test_core.py
â”‚       â”œâ”€â”€ test_database.py
â”‚       â”œâ”€â”€ test_dedup.py
â”‚       â”œâ”€â”€ test_error_handling.py
â”‚       â”œâ”€â”€ test_export.py
â”‚       â”œâ”€â”€ test_export_advanced.py
â”‚       â”œâ”€â”€ test_filtering.py
â”‚       â”œâ”€â”€ test_gallery_utils.py
â”‚       â”œâ”€â”€ test_gpu_e2e.py
â”‚       â”œâ”€â”€ test_handlers.py
â”‚       â”œâ”€â”€ test_integration.py
â”‚       â”œâ”€â”€ test_integration_sam3_patches.py
â”‚       â”œâ”€â”€ test_launch_config.py
â”‚       â”œâ”€â”€ test_managers.py
â”‚       â”œâ”€â”€ test_managers_extended.py
â”‚       â”œâ”€â”€ test_mask_propagator_logic.py
â”‚       â”œâ”€â”€ test_pipelines.py
â”‚       â”œâ”€â”€ test_pipelines_extended.py
â”‚       â”œâ”€â”€ test_progress.py
â”‚       â”œâ”€â”€ test_sam3_wrapper.py
â”‚       â”œâ”€â”€ test_scene_detection.py
â”‚       â”œâ”€â”€ test_scene_utils.py
â”‚       â”œâ”€â”€ test_scene_utils_helpers.py
â”‚       â”œâ”€â”€ test_shared.py
â”‚       â”œâ”€â”€ test_signatures.py
â”‚       â”œâ”€â”€ test_smoke.py
â”‚       â”œâ”€â”€ test_subject_masker_coverage.py
â”‚       â”œâ”€â”€ test_ui_unit.py
â”‚       â””â”€â”€ test_utils.py
â”œâ”€â”€ ui
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app_ui.py
â”‚   â”œâ”€â”€ gallery_utils.py
â”‚   â”œâ”€â”€ handlers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ scene_handler.py
â”‚   â””â”€â”€ tabs
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ extraction_tab.py
â”‚       â”œâ”€â”€ filtering_tab.py
â”‚       â”œâ”€â”€ metrics_tab.py
â”‚       â”œâ”€â”€ scene_tab.py
â”‚       â””â”€â”€ subject_tab.py
â””â”€â”€ verification
    â””â”€â”€ e2e_output
        â”œâ”€â”€ frame_map.json
        â”œâ”€â”€ mask_metadata.json
        â”œâ”€â”€ masks
        â”œâ”€â”€ previews
        â”œâ”€â”€ progress.json
        â”œâ”€â”€ run_config.json
        â”œâ”€â”€ scene_seeds.json
        â”œâ”€â”€ scenes.json
        â”œâ”€â”€ terminal_log.txt
        â””â”€â”€ thumbs
```

## Code Skeleton Reference

### `ðŸ“„ app.py`

```python
"""Frame Extractor & Analyzer v2.0"""
project_root = Path(__file__).parent
def cleanup_models(model_registry):
    """Clears the model registry and performs garbage collection."""
def parse_args():
    """Parses command-line arguments."""
def main():
    """Main entry point for the application."""
```

### `ðŸ“„ core/batch_manager.py`

```python
class BatchStatus(Enum):
    PENDING = "<REDACTED_STRING>"
    PROCESSING = "<REDACTED_STRING>"
    COMPLETED = "<REDACTED_STRING>"
    FAILED = "<REDACTED_STRING>"
    CANCELLED = "<REDACTED_STRING>"
@dataclass
class BatchItem:
    """Represents a single item in the batch processing queue."""
class BatchManager:
    """Manages a queue of batch processing tasks."""
    def __init__(self):
        """Initializes the BatchManager."""
    def add_paths(self, paths: List[str]):
        """Adds a list of file paths to the batch queue."""
    def get_queue_snapshot(self) -> List[BatchItem]:
        """Returns a thread-safe snapshot of the current queue."""
    def get_status_list(self) -> List[List]:
        """Returns a simplified list of status data for the UI."""
    def clear_completed(self):
        """Removes completed, failed, and cancelled items from the queue."""
    def clear_all(self):
        """Clears all items from the queue."""
    def update_progress(self, item_id: str, fraction: float, message: Optional[str]=None):
        """Updates the progress of a specific batch item."""
    def set_status(self, item_id: str, status: BatchStatus, message: Optional[str]=None):
        """Updates the status and message of a specific batch item."""
    def start_processing(self, processor_func: Callable, max_workers: int=1):
        """Starts processing the batch queue in a background thread."""
    def _run_scheduler(self, processor_func, max_workers): ...
    def stop_processing(self):
        """Signals the scheduler to stop processing."""
```

### `ðŸ“„ core/config.py`

```python
"""Configuration Management for Frame Extractor & Analyzer"""
def json_config_settings_source() -> Dict[str, Any]:
    """Loads settings from a JSON file for Pydantic settings."""
class Config(BaseSettings):
    """Manages the application's configuration settings."""
    model_config = SettingsConfigDict(env_file='.env', env_prefix='APP_', env_nes...
    def model_post_init(self, __context: Any) -> None:
        """Post-initialization hook to validate paths."""
    def _validate_paths(self):
        """Ensures critical directories exist and are writable."""
    @model_validator(mode='after')
    def _validate_config(self) -> 'Config':
        """Validates that at least one quality weight is non-zero."""
    @property
    def quality_weights(self) -> Dict[str, int]:
        """Returns a dictionary of quality metric weights."""
```

### `ðŸ“„ core/database.py`

```python
class Database:
    CURRENT_VERSION = 2
    def __init__(self, db_path: Path, batch_size: int=50):
        """Initializes the Database manager."""
    def connect(self):
        """Connects to the SQLite database."""
    def close(self):
        """Closes the database connection."""
    def migrate(self):
        """Applies database migrations to reach the current version."""
    def _detect_legacy_version(self, cursor) -> int:
        """Detects the schema version of a legacy database."""
    def _migration_v1_initial_schema(self, cursor):
        """Migration v1: Create initial metadata table and indexes."""
    def _migration_v2_add_error_severity(self, cursor):
        """Migration v2: Add error_severity column."""
    def clear_metadata(self):
        """Deletes all records from the metadata table."""
    def insert_metadata(self, metadata: Dict[str, Any]):
        """Inserts or replaces a metadata record."""
    def flush(self):
        """Manually flush the buffer."""
    def _flush_buffer(self):
        """Internal method to write buffered records to the database."""
    def load_all_metadata(self) -> List[Dict[str, Any]]:
        """Loads all metadata from the database."""
    def count_errors(self) -> int:
        """Counts the number of records with errors."""
```

### `ðŸ“„ core/error_handling.py`

```python
"""Error Handling Infrastructure for Frame Extractor & Analyzer"""
class ErrorSeverity(Enum):
    LOW = "<REDACTED_STRING>"
    MEDIUM = "<REDACTED_STRING>"
    HIGH = "<REDACTED_STRING>"
    CRITICAL = "<REDACTED_STRING>"
class RecoveryStrategy(Enum):
    RETRY = "<REDACTED_STRING>"
    FALLBACK = "<REDACTED_STRING>"
    SKIP = "<REDACTED_STRING>"
    ABORT = "<REDACTED_STRING>"
class ErrorHandler:
    def __init__(self, logger: 'AppLogger', max_attempts: int, backoff_seconds: list):
        """Initializes the ErrorHandler."""
    def with_retry(self, max_attempts: Optional[int]=None, backoff_seconds: Optional[list]=None, recoverable_exceptions: tuple=(Exception,)):
        """Decorator that retries the function call upon failure."""
    def with_fallback(self, fallback_func: Callable):
        """Decorator that executes a fallback function if the primary function fails."""
```

### `ðŸ“„ core/events.py`

```python
"""Event Models for Frame Extractor & Analyzer"""
class UIEvent(BaseModel):
    """Base class for all UI-triggered events."""
    model_config = ConfigDict(validate_assignment=True, extra='ignore', str_strip...
class ExtractionEvent(UIEvent):
    """Data model for frame extraction events."""
class PreAnalysisEvent(UIEvent):
    """Data model for pre-analysis configuration and execution."""
    @field_validator('face_ref_img_path')
    @classmethod
    def validate_face_ref(cls, v: str, info) -> str:
        """Validates that the reference image path is a valid image file."""
    @model_validator(mode='after')
    def validate_strategy_consistency(self) -> 'PreAnalysisEvent':
        """Ensures that dependent settings (like face filter) are consistent with availa..."""
class PropagationEvent(UIEvent):
    """Data model for the mask propagation stage."""
class FilterEvent(UIEvent):
    """Data model for filtering and gallery update events."""
class ExportEvent(UIEvent):
    """Data model for exporting filtered frames."""
class SessionLoadEvent(UIEvent):
    """Data model for loading a previous session."""
```

### `ðŸ“„ core/export.py`

```python
def _perform_ffmpeg_export(video_path: str, frames_to_extract: list, export_dir: Path, logger: 'AppLogger') -> tuple[bool, Optional[str]]: ...
def _rename_exported_frames(export_dir: Path, frames_to_extract: list, fn_to_orig_map: dict, logger: 'AppLogger'): ...
def _export_metadata(kept_frames: list, export_dir: Path, logger: 'AppLogger'): ...
def _crop_exported_frames(kept_frames: list, export_dir: Path, crop_ars: str, crop_padding: int, masks_root: Path, logger: 'AppLogger', cancel_event) -> int: ...
def export_kept_frames(event: ExportEvent, config: 'Config', logger: 'AppLogger', thumbnail_manager, cancel_event) -> str: ...
def dry_run_export(event: ExportEvent, config: 'Config') -> str: ...
```

### `ðŸ“„ core/filtering.py`

```python
def load_and_prep_filter_data(output_dir: str, get_all_filter_keys: Callable, config: 'Config') -> tuple[list, dict]:
    """Loads metadata from the database and prepares histograms for the UI."""
def histogram_svg(hist_data: tuple, title: str='', logger: Optional['AppLogger']=None) -> str:
    """Generates an SVG string of a histogram plot."""
def build_all_metric_svgs(per_metric_values: dict, get_all_filter_keys: Callable, logger: 'AppLogger') -> dict:
    """Builds histogram SVGs for all available metrics."""
def _extract_metric_arrays(all_frames_data: list[dict], config: 'Config') -> dict:
    """Extracts numerical arrays for each metric from the list of frame data dicts."""
def _run_batched_lpips(pairs: list[tuple[int, int]], all_frames_data: list[dict], dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', output_dir: str, threshold: float, device: str='cpu'):
    """Runs LPIPS deduplication on a list of pairs in batches using GPU if available."""
def _apply_deduplication_filter(all_frames_data: list[dict], filters: dict, thumbnail_manager: 'ThumbnailManager', config: 'Config', output_dir: str) -> tuple[np.ndarray, defaultdict]:
    """Applies deduplication logic (pHash, SSIM, or LPIPS) to filter out similar fra..."""
def _apply_metric_filters(all_frames_data: list[dict], metric_arrays: dict, filters: dict, config: 'Config') -> tuple[np.ndarray, defaultdict]:
    """Applies threshold-based filtering on scalar metrics."""
def apply_all_filters_vectorized(all_frames_data: list[dict], filters: dict, config: 'Config', thumbnail_manager: Optional['ThumbnailManager']=None, output_dir: Optional[str]=None) -> tuple[list, list, Counter, dict]:
    """Main entry point for filtering frames based on deduplication and metric thres..."""
def _generic_dedup(all_frames_data: list[dict], dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', output_dir: str, compare_fn: Callable[[np.ndarray, np.ndarray], bool]) -> tuple[np.ndarray, defaultdict]:
    """Generic deduplication helper that compares adjacent frames using a custom fun..."""
def _ssim_compare(img1: np.ndarray, img2: np.ndarray, threshold: float) -> bool:
    """Compares two images using SSIM."""
def apply_ssim_dedup(all_frames_data: list[dict], filters: dict, dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', config: 'Config', output_dir: str) -> tuple[np.ndarray, defaultdict]:
    """Applies SSIM-based deduplication."""
def apply_lpips_dedup(all_frames_data: list[dict], filters: dict, dedup_mask: np.ndarray, reasons: defaultdict, thumbnail_manager: 'ThumbnailManager', config: 'Config', output_dir: str) -> tuple[np.ndarray, defaultdict]:
    """Applies LPIPS-based deduplication."""
```

### `ðŸ“„ core/logger.py`

```python
"""Logging Infrastructure for Frame Extractor & Analyzer"""
SUCCESS_LEVEL_NUM = 25
class LogEvent(BaseModel):
    """Represents a structured log entry."""
class ColoredFormatter(logging.Formatter):
    """Custom formatter that adds colors to log levels."""
    COLORS = {'DEBUG': '\x1b[36m', 'INFO': '\x1b[37m', 'WARNING': '\x1b[33m', 'ER...
    def format(self, record: logging.LogRecord) -> str:
        """Formats the log record with color codes."""
class JsonFormatter(logging.Formatter):
    """Formatter that outputs logs as JSON strings."""
    def format(self, record: logging.LogRecord) -> str:
        """Formats the log record as a JSON string."""
class AppLogger:
    """A streamlined logger for the application, consolidating output into a single ..."""
    def __init__(self, config: 'Config', log_dir: Optional[Path]=None, log_to_file: bool=True, log_to_console: bool=True):
        """Initializes the AppLogger."""
    def set_progress_queue(self, queue: Queue):
        """Sets the queue used for sending logs to the UI."""
    def _create_log_event(self, level: str, message: str, component: str, **kwargs) -> LogEvent:
        """Helper to create a structured LogEvent object."""
    def _log_event(self, event: LogEvent):
        """Dispatches the LogEvent to standard logging and the UI queue."""
    def debug(self, message: str, component: str='system', **kwargs): ...
    def info(self, message: str, component: str='system', **kwargs): ...
    def warning(self, message: str, component: str='system', **kwargs): ...
    def error(self, message: str, component: str='system', **kwargs): ...
    def success(self, message: str, component: str='system', **kwargs): ...
    def critical(self, message: str, component: str='system', **kwargs): ...
    def copy_log_to_output(self, output_dir: Path):
        """No longer needed with consolidated logging."""
```

### `ðŸ“„ core/managers.py`

```python
build_sam3_video_predictor = None
Sam3VideoPredictor = None
def _setup_triton_mock():
    """Create a mock triton module if triton is not available (Windows)."""
_triton_mocked = _setup_triton_mock()
class ThumbnailManager:
    """Manages an in-memory LRU cache for image thumbnails."""
    def __init__(self, logger: 'AppLogger', config: 'Config'):
        """Initializes the manager with a configurable cache size."""
    def get(self, thumb_path: Path) -> Optional[np.ndarray]:
        """Retrieves a thumbnail from cache or loads it from disk."""
    def clear_cache(self):
        """Clears the thumbnail cache and triggers garbage collection."""
    def _cleanup_old_entries(self): ...
class ModelRegistry:
    """Thread-safe registry for lazy loading and caching of heavy ML models."""
    def __init__(self, logger: Optional['AppLogger']=None): ...
    def lock(self, key: str):
        """Prevents a model from being cleared by the watchdog."""
    def unlock(self, key: str):
        """Allows a model to be cleared by the watchdog again."""
    def get_or_load(self, key: str, loader_fn: Callable[[], Any]) -> Any:
        """Retrieves a model by key, loading it via loader_fn if not present."""
    def check_memory_usage(self, config: 'Config'):
        """Monitors system and GPU memory usage. """
    def clear(self, force: bool=True):
        """Clears loaded models from the registry."""
    def get_tracker(self, model_name: str, models_path: str, user_agent: str, retry_params: tuple, config: 'Config') -> Optional['SAM3Wrapper']:
        """Gets or loads the SAM3 tracker, handling CPU fallback on CUDA OOM."""
    def _load_tracker_impl(self, model_name: str, models_path: str, user_agent: str, retry_params: tuple, device: str, config: 'Config') -> 'SAM3Wrapper': ...
class SAM3Wrapper:
    """SAM3 Tracker using official Sam3VideoPredictor API."""
    def __init__(self, checkpoint_path=None, device='cuda'):
        """Initialize SAM3 wrapper using build_sam3_video_predictor."""
    def init_video(self, video_resource: Union[str, list]):
        """Initialize inference session with video, frame directory, or list of images."""
    def add_bbox_prompt(self, frame_idx: int, obj_id: int, bbox_xywh: list, img_size: tuple, text: Optional[str]=None) -> np.ndarray:
        """Add bounding box prompt at specified frame."""
    def propagate(self, start_idx: int=0, max_frames: int=None, direction: str='forward'):
        """Generator yielding masks for each frame during propagation."""
    def clear_prompts(self):
        """Reset all prompts in current session."""
    def detect_objects(self, frame_rgb: np.ndarray, prompt: str) -> list:
        """Detect objects in a single frame using text prompt."""
    def add_text_prompt(self, frame_idx: int, text: str) -> dict:
        """Add text prompt for video object detection using new API."""
    def add_point_prompt(self, frame_idx: int, obj_id: int, points: list, labels: list, img_size: tuple) -> np.ndarray:
        """Add point prompts for mask refinement using new API."""
    def remove_object(self, obj_id: int):
        """Remove an object from the tracking session."""
    def reset_session(self):
        """Reset all prompts and results (clears session state)."""
    def close_session(self):
        """Close the inference session and free GPU resources."""
    def shutdown(self):
        """Shutdown the predictor, release memory, and clean up all resources."""
thread_local = threading.local()
def get_face_landmarker(model_path: str, logger: 'AppLogger') -> vision.FaceLandmarker:
    """Returns a thread-local MediaPipe FaceLandmarker instance."""
def get_face_analyzer(model_name: str, models_path: str, det_size_tuple: tuple, logger: 'AppLogger', model_registry: 'ModelRegistry', device: str='cpu') -> 'FaceAnalysis':
    """Gets or loads the InsightFace FaceAnalysis app, with OOM handling."""
def get_lpips_metric(model_name: str='alex', device: str='cpu') -> torch.nn.Module:
    """Returns the LPIPS metric model."""
def initialize_analysis_models(params: 'AnalysisParameters', config: 'Config', logger: 'AppLogger', model_registry: 'ModelRegistry') -> dict:
    """Initializes all necessary analysis models based on parameters."""
class VideoManager:
    """Handles video preparation and metadata extraction."""
    def __init__(self, source_path: str, config: 'Config', max_resolution: Optional[str]=None): ...
    def prepare_video(self, logger: 'AppLogger') -> str:
        """Prepares the video for processing."""
    @staticmethod
    def get_video_info(video_path: str) -> dict:
        """Extracts metadata (FPS, dimensions, frame count) from the video file."""
```

### `ðŸ“„ core/models.py`

```python
def _coerce(val: Any, to_type: type) -> Any:
    """Helper to strictly coerce values to the target type."""
def _sanitize_face_ref(kwargs: dict, logger: 'AppLogger') -> tuple[str, bool]:
    """Validates the face reference image path."""
class QualityConfig(BaseModel):
    """Configuration for quality metric normalization."""
class FrameMetrics(BaseModel):
    """Container for calculated quality scores for a frame."""
class Frame(BaseModel):
    """Represents a single video frame and its associated metadata."""
    model_config = ConfigDict(arbitrary_types_allowed=True)
    def calculate_quality_metrics(self, thumb_image_rgb: np.ndarray, quality_config: 'QualityConfig', logger: 'AppLogger', mask: Optional[np.ndarray]=None, niqe_metric: Optional[Callable]=None, main_config: Optional['Config']=None, face_landmarker: Optional[Callable]=None, face_bbox: Optional[List[int]]=None, metrics_to_compute: Optional[Dict[str, bool]]=None):
        """Computes various image quality metrics (sharpness, contrast, NIQE, etc.) for ..."""
class Scene(BaseModel):
    """Represents a detected scene or shot in the video."""
class SceneState:
    """Wrapper to manage state transitions and updates for a Scene object."""
    def __init__(self, scene_data: Union[dict, Scene]): ...
    @property
    def data(self) -> dict:
        """Returns the scene data as a dictionary."""
    @property
    def scene(self) -> Scene:
        """Returns the underlying Scene object."""
    def set_manual_bbox(self, bbox: list[int], source: str):
        """Overrides the automatically selected subject bounding box."""
    def reset(self):
        """Resets the scene to its initial state (undoes manual overrides)."""
    def include(self):
        """Marks the scene as included."""
    def exclude(self):
        """Marks the scene as excluded."""
    def update_seed_result(self, bbox: Optional[list[int]], details: dict):
        """Updates the seeding result (detected subject) for the scene."""
class AnalysisParameters(BaseModel):
    """Aggregates all parameters for the analysis pipeline."""
    @classmethod
    def from_ui(cls, logger: 'AppLogger', config: 'Config', **kwargs) -> 'AnalysisParameters':
        """Factory method to create parameters from UI arguments, handling validation an..."""
class MaskingResult(BaseModel):
    """Result of the mask propagation process for a frame."""
```

### `ðŸ“„ core/pipelines.py`

```python
def _process_ffmpeg_stream(stream, tracker: Optional['AdvancedProgressTracker'], desc: str, total_duration_s: float):
    """Parses FFmpeg progress stream and updates the tracker."""
def _process_ffmpeg_showinfo(stream, fps: float) -> tuple[list, str]:
    """Parses FFmpeg stderr for 'showinfo' frame timestamps to map back to original ..."""
def run_ffmpeg_extraction(video_path: str, output_dir: Path, video_info: dict, params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, logger: 'AppLogger', config: 'Config', tracker: Optional['AdvancedProgressTracker']=None):
    """Executes FFmpeg command to extract frames/thumbnails."""
class Pipeline:
    """Base class for processing pipelines."""
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event): ...
class ExtractionPipeline(Pipeline):
    """Pipeline for extracting frames from video or processing image folders."""
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, model_registry: Optional['ModelRegistry']=None): ...
    def _run_impl(self, tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """Internal execution logic for extraction."""
class AnalysisPipeline(Pipeline):
    """Pipeline for analyzing frames (pre-analysis, propagation, full analysis)."""
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'): ...
    def _initialize_niqe_metric(self):
        """Lazy initialization of the NIQE metric model."""
    def run_full_analysis(self, scenes_to_process: list['Scene'], tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """Runs the mask propagation phase."""
    def run_analysis_only(self, scenes_to_process: list['Scene'], tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """Runs the frame analysis phase (calculating quality metrics)."""
    def _filter_completed_scenes(self, scenes: list['Scene'], progress_data: dict) -> list['Scene']:
        """Removes scenes that have already been processed when resuming."""
    def _save_progress_bulk(self, completed_scene_ids: list[int], progress_file: Path):
        """Updates the progress file with a list of completed scene IDs."""
    def _process_reference_face(self):
        """Computes the embedding for the reference face image."""
    def _run_image_folder_analysis(self, tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """Specialized execution path for image folder inputs."""
    def _run_analysis_loop(self, scenes_to_process: list['Scene'], metrics_to_compute: dict, tracker: Optional['AdvancedProgressTracker']=None):
        """Orchestrates the parallel processing of frames for metric calculation."""
    def _process_batch(self, batch_paths: list[Path], metrics_to_compute: dict) -> int:
        """Processes a batch of frame files."""
    def _process_single_frame(self, thumb_path: Path, metrics_to_compute: dict):
        """Analyzes a single frame: computes metrics, face similarity, and stores metadata."""
    def _analyze_face_similarity(self, frame: 'Frame', image_rgb: np.ndarray) -> Optional[list[int]]:
        """Computes face similarity and confidence against the reference face."""
def _handle_extraction_uploads(event_dict: dict, config: 'Config') -> dict:
    """Handles video file uploads and updates the event dictionary."""
def _initialize_extraction_params(event_dict: dict, config: 'Config', logger: 'AppLogger') -> tuple[AnalysisParameters, AdvancedProgressTracker]:
    """Initializes analysis parameters and progress tracker for extraction."""
@handle_common_errors
def execute_extraction(event: 'ExtractionEvent', progress_queue: Queue, cancel_event: threading.Event, logger: 'AppLogger', config: 'Config', thumbnail_manager: Optional['ThumbnailManager']=None, cuda_available: Optional[bool]=None, progress: Optional[Callable]=None, model_registry: Optional['ModelRegistry']=None) -> Generator[dict, None, None]:
    """Orchestrates the frame extraction process."""
def _handle_pre_analysis_uploads(event_dict: dict, config: 'Config') -> dict:
    """Handles face reference image uploads and updates the event dictionary."""
def _initialize_pre_analysis_params(event_dict: dict, config: 'Config', logger: 'AppLogger') -> tuple[AnalysisParameters, Path]:
    """Initializes analysis parameters and ensures output directory exists."""
def _load_scenes(output_dir: Path) -> list[Scene]:
    """Loads scenes from scenes.json."""
class PreAnalysisPipeline(Pipeline):
    """Pipeline for pre-analyzing scenes (best frame selection, seeding)."""
    def __init__(self, config: 'Config', logger: 'AppLogger', params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'): ...
    def run(self, scenes: list[Scene], tracker: Optional['AdvancedProgressTracker']=None) -> list[Scene]:
        """Runs pre-analysis for a list of scenes."""
    def _initialize_niqe_if_needed(self, device: str, is_folder_mode: bool):
        """Lazy initialization of NIQE for seeding."""
    def _process_single_scene(self, scene: Scene, masker: SubjectMasker, previews_dir: Path, is_folder_mode: bool):
        """Processes a single scene: selects best frame, generates seed, and preview."""
@handle_common_errors
def execute_pre_analysis(event: 'PreAnalysisEvent', progress_queue: Queue, cancel_event: threading.Event, logger: 'AppLogger', config: 'Config', thumbnail_manager: 'ThumbnailManager', cuda_available: bool, progress: Optional[Callable]=None, model_registry: 'ModelRegistry'=None) -> Generator[dict, None, None]:
    """Orchestrates the pre-analysis phase (scene detection, subject seeding)."""
def validate_session_dir(path: Union[str, Path]) -> tuple[Optional[Path], Optional[str]]:
    """Checks if the provided path is a valid session directory."""
def execute_session_load(event: 'SessionLoadEvent', logger: 'AppLogger') -> dict:
    """Loads session state from disk."""
def _load_analysis_scenes(scenes_data: list, is_folder_mode: bool, include_only: bool=True) -> list[Scene]:
    """Converts raw scene data to Scene objects, optionally filtering by status."""
def _initialize_analysis_pipeline(config: 'Config', logger: 'AppLogger', params: AnalysisParameters, progress_queue: Queue, cancel_event: threading.Event, thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry') -> AnalysisPipeline:
    """Creates and returns an AnalysisPipeline instance."""
def execute_propagation(event: PropagationEvent, progress_queue: Queue, cancel_event: threading.Event, logger: AppLogger, config: Config, thumbnail_manager, cuda_available, progress=None, model_registry: 'ModelRegistry'=None) -> Generator[dict, None, None]:
    """Orchestrates the mask propagation stage."""
@handle_common_errors
def execute_analysis(event: PropagationEvent, progress_queue: Queue, cancel_event: threading.Event, logger: AppLogger, config: Config, thumbnail_manager, cuda_available, progress=None, model_registry: 'ModelRegistry'=None) -> Generator[dict, None, None]:
    """Orchestrates the frame analysis stage."""
```

### `ðŸ“„ core/progress.py`

```python
"""Progress Tracking Infrastructure for Frame Extractor & Analyzer"""
class ProgressEvent(BaseModel): ...
class AdvancedProgressTracker:
    """Tracks and estimates progress for long-running operations."""
    def __init__(self, progress: Callable, queue: Queue, logger: 'AppLogger', ui_stage_name: str=''):
        """Initializes the progress tracker."""
    def start(self, total_items: int, desc: Optional[str]=None):
        """Resets the tracker for a new operation."""
    def step(self, n: int=1, desc: Optional[str]=None, substage: Optional[str]=None):
        """Increments progress by 'n' steps."""
    def set(self, done: int, desc: Optional[str]=None, substage: Optional[str]=None):
        """Sets the absolute number of completed steps."""
    def set_stage(self, stage: str, substage: Optional[str]=None):
        """Updates the current stage description without changing progress."""
    def done_stage(self, final_text: Optional[str]=None):
        """Marks the current operation as complete."""
    def _overlay(self, force: bool=False):
        """Emits a progress update if enough time has passed (throttling)."""
    def _eta_seconds(self) -> Optional[float]:
        """Calculates estimated seconds remaining based on EMA."""
    @staticmethod
    def _fmt_eta(eta_s: Optional[float]) -> str:
        """Formats seconds into a human-readable string."""
```

### `ðŸ“„ core/sam3_patches.py`

```python
"""SAM3 Compatibility Patches for Windows"""
def edt_triton_fallback(data):
    """OpenCV-based fallback for Euclidean Distance Transform when Triton unavailable"""
def connected_components_fallback(input_tensor):
    """CPU-based fallback for connected components when Triton unavailable"""
def set_image_patched(self, image):
    """Patched version of Sam3Processor.set_image to handle HWC inputs correctly."""
def apply_patches():
    """Apply monkey patches to SAM3 if Triton is not available, AND fix image proces..."""
```

### `ðŸ“„ core/scene_utils/__init__.py`

```python
"""Scene utilities package for Frame Extractor & Analyzer."""
__all__ = ['run_scene_detection', 'make_photo_thumbs', 'MaskPropagator', 'See...
```

### `ðŸ“„ core/scene_utils/detection.py`

```python
"""Scene detection and thumbnail generation utilities."""
def run_scene_detection(video_path: str, output_dir: Path, logger: 'AppLogger') -> list:
    """Detect scene changes in a video using PySceneDetect."""
def make_photo_thumbs(image_paths: list[Path], out_dir: Path, params: 'AnalysisParameters', cfg: 'Config', logger: 'AppLogger', tracker: Optional['AdvancedProgressTracker']=None) -> dict:
    """Generate thumbnails for a list of images."""
```

### `ðŸ“„ core/scene_utils/helpers.py`

```python
"""Helper functions for scene processing."""
def draw_boxes_preview(img: np.ndarray, boxes_xyxy: list[list[int]], cfg: 'Config') -> np.ndarray:
    """Draw bounding boxes on an image for preview."""
def save_scene_seeds(scenes_list: list['Scene'], output_dir_str: str, logger: 'AppLogger') -> None:
    """Save scene seed information to JSON file."""
def get_scene_status_text(scenes_list: list['Scene']) -> tuple[str, Any]:
    """Generate status text and button update for scene list."""
def toggle_scene_status(scenes_list: list['Scene'], selected_shot_id: int, new_status: str, output_folder: str, logger: 'AppLogger') -> tuple[list, str, str, Any]:
    """Toggle the status of a selected scene."""
def _create_analysis_context(config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager', cuda_available: bool, ana_ui_map_keys: list[str], ana_input_components: list, model_registry: 'ModelRegistry') -> 'SubjectMasker':
    """Helper to initialize a SubjectMasker from UI arguments."""
def _recompute_single_preview(scene_state: 'SceneState', masker: 'SubjectMasker', overrides: dict, thumbnail_manager: 'ThumbnailManager', logger: 'AppLogger'):
    """Re-runs the seeding process for a single scene and updates its preview image."""
def _wire_recompute_handler(config: 'Config', logger: 'AppLogger', thumbnail_manager: 'ThumbnailManager', scenes: list['Scene'], shot_id: int, outdir: str, text_prompt: str, view: str, ana_ui_map_keys: list[str], ana_input_components: list, cuda_available: bool, model_registry: 'ModelRegistry') -> tuple:
    """Gradio event handler for the 'Recompute' button in the scene editor."""
```

### `ðŸ“„ core/scene_utils/mask_propagator.py`

```python
"""MaskPropagator class for propagating segmentation masks across video frames."""
class MaskPropagator:
    """Propagates segmentation masks from a seed frame to surrounding frames."""
    def __init__(self, params: 'AnalysisParameters', dam_tracker: 'SAM3Wrapper', cancel_event: threading.Event, progress_queue: Queue, config: 'Config', logger: 'AppLogger', device: str='cpu', model_registry: Optional['ModelRegistry']=None):
        """Initialize the MaskPropagator."""
    def propagate_video(self, video_path: str, frame_numbers: list[int], prompts: list[dict], frame_size: tuple[int, int], frame_map: dict[int, str], tracker: Optional['AdvancedProgressTracker']=None) -> tuple[dict, dict, dict, dict]:
        """Propagate masks using the video file directly (no temp JPEG I/O)."""
    def propagate(self, shot_frames_rgb: list[np.ndarray], seed_idx: int, bbox_xywh: list[int], tracker: Optional['AdvancedProgressTracker']=None, additional_seeds: Optional[list[dict]]=None, frame_numbers: Optional[list[int]]=None) -> tuple[list, list, list, list]:
        """Legacy method: Propagate masks from a seed frame using in-memory frames."""
```

### `ðŸ“„ core/scene_utils/seed_selector.py`

```python
"""SeedSelector class for selecting seed frames and bounding boxes for mask prop..."""
class SeedSelector:
    """Selects seed frames and bounding boxes for mask propagation."""
    def __init__(self, params: 'AnalysisParameters', config: 'Config', face_analyzer: 'FaceAnalysis', reference_embedding: np.ndarray, tracker: 'SAM3Wrapper', logger: 'AppLogger', device: str='cpu'):
        """Initialize the SeedSelector."""
    def _get_param(self, source: Union[dict, object], key: str, default: Any=None) -> Any:
        """Get a parameter from either a dict or an object."""
    def select_seed(self, frame_rgb: np.ndarray, current_params: Optional[dict]=None, scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """Select a seed bounding box for the given frame."""
    def _face_with_text_fallback_seed(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """Try face-first, fall back to text prompt if face not found."""
    def _identity_first_seed(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """Find subject by matching to reference face."""
    def _object_first_seed(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """Find subject using text prompt, validated by person detection."""
    def _find_target_face(self, frame_rgb: np.ndarray) -> tuple[Optional[dict], dict]:
        """Find the target face in frame that matches reference embedding."""
    def _get_person_boxes(self, frame_rgb: np.ndarray, scene: Optional['Scene']=None) -> list[dict]:
        """Get person bounding boxes from scene cache or detection."""
    def _get_text_prompt_boxes(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters']) -> tuple[list[dict], dict]:
        """Get bounding boxes from text prompt detection."""
    def _score_and_select_candidate(self, frame_rgb: np.ndarray, target_face: dict, person_boxes: list[dict], text_boxes: list[dict]) -> tuple[Optional[list], dict]:
        """Score and select the best candidate box that contains the target face."""
    def _choose_person_by_strategy(self, frame_rgb: np.ndarray, params: Union[dict, 'AnalysisParameters'], scene: Optional['Scene']=None) -> tuple[list, dict]:
        """Select person using configurable strategy."""
    def _load_image_from_array(self, image_rgb: np.ndarray) -> tuple[np.ndarray, torch.Tensor]:
        """Load image for model input."""
    def _calculate_iou(self, box1: list, box2: list) -> float:
        """Calculate IoU between two boxes in xyxy format."""
    def _box_contains(self, cb: list, ib: list) -> bool:
        """Check if container box (cb) contains inner box (ib)."""
    def _expand_face_to_body(self, face_bbox: list, img_shape: tuple) -> list[int]:
        """Expand a face bounding box to approximate body bounding box."""
    def _final_fallback_box(self, img_shape: tuple) -> list[int]:
        """Return a fallback bounding box when no subject is found."""
    def _xyxy_to_xywh(self, box: list, img_shape: Optional[tuple]=None) -> list[int]:
        """Convert box from xyxy to xywh format with optional padding and clamping."""
    def _get_mask_for_bbox(self, frame_rgb_small: np.ndarray, bbox_xywh: list) -> Optional[np.ndarray]:
        """Generate a mask for the given bounding box using SAM3."""
```

### `ðŸ“„ core/scene_utils/subject_masker.py`

```python
"""SubjectMasker class for coordinating subject detection and mask propagation."""
class SubjectMasker:
    """Coordinates subject detection and mask propagation for video frames."""
    def __init__(self, params: 'AnalysisParameters', progress_queue: Queue, cancel_event: threading.Event, config: 'Config', frame_map: Optional[dict]=None, face_analyzer: Optional['FaceAnalysis']=None, reference_embedding: Optional[np.ndarray]=None, thumbnail_manager: Optional['ThumbnailManager']=None, niqe_metric: Optional[Callable]=None, logger: Optional['AppLogger']=None, face_landmarker: Optional['FaceLandmarker']=None, device: str='cpu', model_registry: 'ModelRegistry'=None):
        """Initialize SubjectMasker."""
    def initialize_models(self) -> None:
        """Initialize required models based on parameters."""
    def _initialize_tracker(self) -> bool:
        """Initialize the SAM3 tracker."""
    def run_propagation(self, frames_dir: str, scenes_to_process: list['Scene'], tracker: Optional['AdvancedProgressTracker']=None) -> dict:
        """Run mask propagation for all scenes."""
    def _load_shot_frames(self, frames_dir: str, thumb_dir: Path, start: int, end: int) -> list[tuple[int, np.ndarray, tuple[int, int]]]:
        """Load frames for a shot from disk."""
    def _get_thumb_for_frame(self, thumb_dir: Path, frame_num: int) -> Optional[np.ndarray]:
        """Retrieve a thumbnail for a specific frame number."""
    def _select_best_frame_in_scene(self, scene: 'Scene', frames_dir: str) -> None:
        """Select the best frame in a scene for seeding."""
    def get_seed_for_frame(self, frame_rgb: np.ndarray, seed_config: dict=None, scene: Optional['Scene']=None) -> tuple[Optional[list], dict]:
        """Get seed bounding box for a frame."""
    def get_mask_for_bbox(self, frame_rgb_small: np.ndarray, bbox_xywh: list) -> Optional[np.ndarray]:
        """Generate a mask for a bounding box."""
    def draw_bbox(self, img_rgb: np.ndarray, xywh: list, color: Optional[tuple]=None, thickness: Optional[int]=None, label: Optional[str]=None) -> np.ndarray:
        """Draw a bounding box on an image."""
    def _create_frame_map(self, output_dir: str) -> dict:
        """Create a frame map for the output directory."""
```

### `ðŸ“„ core/shared.py`

```python
"""Shared utilities for Frame Extractor & Analyzer"""
def scene_matches_view(scene: 'Scene', view: str) -> bool:
    """Check if a scene matches the specified view filter."""
def create_scene_thumbnail_with_badge(thumb_img: np.ndarray, scene_idx: int, is_excluded: bool, config: Optional['Config']=None) -> np.ndarray:
    """Create a scene thumbnail with a visual badge indicating exclusion status."""
def scene_caption(scene: Union[dict, 'Scene']) -> str:
    """Generate a caption string for a scene."""
def build_scene_gallery_items(scenes: List[Union[dict, 'Scene']], view: str, output_dir: str, page_num: int=1, page_size: int=20, config: Optional['Config']=None) -> Tuple[List[Tuple], List[int], int]:
    """Build gallery items for scene display."""
```

### `ðŸ“„ core/utils.py`

```python
def handle_common_errors(func: Callable) -> Callable:
    """Decorator to catch common exceptions and return a standardized error dictionary."""
def monitor_memory_usage(logger: 'AppLogger', device: str, threshold_mb: int=8000):
    """Logs a warning and clears cache if GPU memory usage exceeds threshold."""
def validate_video_file(video_path: str) -> bool:
    """Checks if the video file exists, is not empty, and can be opened by OpenCV."""
def estimate_totals(params: 'AnalysisParameters', video_info: dict, scenes: Optional[list['Scene']]) -> dict:
    """Estimates the total work items for each pipeline stage."""
def sanitize_filename(name: str, config: 'Config', max_length: Optional[int]=None) -> str:
    """Sanitizes a string to be safe for use as a filename."""
def _to_json_safe(obj: Any) -> Any:
    """Recursively converts objects (NumPy types, Path, etc.) to JSON-serializable t..."""
@contextlib.contextmanager
def safe_resource_cleanup(device: str='cpu'):
    """Context manager to ensure garbage collection and CUDA cache clearing."""
def is_image_folder(p: Union[str, Path]) -> bool:
    """Checks if the path points to a directory."""
def list_images(p: Union[str, Path], cfg: Config) -> list[Path]:
    """Lists all valid image files in a directory."""
@njit
def compute_entropy(hist: np.ndarray, entropy_norm: float) -> float:
    """Computes normalized entropy from a histogram using Numba."""
def _compute_sha256(path: Path) -> str:
    """Computes SHA256 hash of a file."""
def download_model(url: str, dest_path: Union[str, Path], description: str, logger: 'AppLogger', error_handler: 'ErrorHandler', user_agent: str, min_size: int=1000000, expected_sha256: Optional[str]=None, token: Optional[str]=None):
    """Downloads a file from a URL with retries, validation, and progress logging."""
def postprocess_mask(mask: np.ndarray, config: 'Config', fill_holes: bool=True, keep_largest_only: bool=True) -> np.ndarray:
    """Cleans up binary masks using morphological operations and connected components."""
def render_mask_overlay(frame_rgb: np.ndarray, mask_gray: np.ndarray, alpha: float, logger: 'AppLogger') -> np.ndarray:
    """overlays a semi-transparent red mask on the image."""
def rgb_to_pil(image_rgb: np.ndarray) -> Image.Image:
    """Converts a NumPy RGB array to a PIL Image."""
@functools.lru_cache(maxsize=4)
def create_frame_map(output_dir: Path, logger: 'AppLogger', ext: str='.webp') -> dict:
    """Creates a mapping from original frame numbers to extracted filenames."""
def draw_bbox(img_rgb: np.ndarray, xywh: list, config: 'Config', color: Optional[tuple]=None, thickness: Optional[int]=None, label: Optional[str]=None) -> np.ndarray:
    """Draws a bounding box and optional label on an image."""
```

### `ðŸ“„ scripts/run_ux_audit.py`

```python
"""Run comprehensive UX audit and generate report."""
def run_tests(test_path: str, extra_args: list=None) -> tuple[int, str]:
    """Run pytest on specified test path and capture output."""
def generate_report(results: dict, output_path: Path) -> None:
    """Generate markdown report from test results."""
def main(): ...
```

### `ðŸ“„ scripts/take_screenshot.py`

```python
async def main(): ...
```

### `ðŸ“„ scripts/verification/e2e_run.py`

```python
class Logger(object):
    def __init__(self, filename): ...
    def write(self, message): ...
    def flush(self): ...
def run_e2e_verification(): ...
```

### `ðŸ“„ scripts/verification/verify_simple.py`

```python
def verify_ui_simple(): ...
```

### `ðŸ“„ scripts/verify_quality.py`

```python
class QualityVerifier:
    def __init__(self, output_dir: Path): ...
    def verify(self) -> Dict[str, Any]: ...
    def _fail(self, msg: str): ...
    def _warn(self, msg: str): ...
    def _check_mask_quality(self): ...
    def _check_db_metrics(self): ...
    def log_history(self): ...
```

### `ðŸ“„ ui/app_ui.py`

```python
class ApplicationState(BaseModel):
    """Consolidated state model for the application."""
class AppUI:
    """Main UI class for the Frame Extractor & Analyzer application."""
    def __init__(self, config: 'Config', logger: 'AppLogger', progress_queue: Queue, cancel_event: threading.Event, thumbnail_manager: 'ThumbnailManager', model_registry: 'ModelRegistry'):
        """Initialize the AppUI."""
    def _handle_exception(self, e: Exception, context: str='Operation') -> dict:
        """Standardized exception handling for UI callbacks."""
    @staticmethod
    def safe_ui_callback(context: str):
        """Decorator to wrap UI callbacks with error handling."""
    def preload_models(self):
        """Asynchronously preloads heavy models (SAM3) in a background thread."""
    def build_ui(self) -> gr.Blocks:
        """Constructs the entire Gradio UI layout."""
    def _get_comp(self, name: str) -> Optional[gr.components.Component]:
        """Retrieves a component by name from the internal registry."""
    def _reg(self, key: str, component: gr.components.Component) -> gr.components.Component:
        """Registers a component for later retrieval by UI mapping key."""
    def _create_component(self, name: str, comp_type: str, kwargs: dict) -> gr.components.Component:
        """Helper to create and register a Gradio component."""
    def _create_section_header(self, title: str, subtitle: str=None, icon: str='ðŸ“‚'):
        """Creates a standardized section header."""
    def _build_header(self):
        """Builds the UI header section with title and status indicators."""
    def _build_main_tabs(self):
        """Constructs the main tabbed interface."""
    def _build_footer(self):
        """Builds the footer with status bar, logs, and help section."""
    def get_all_filter_keys(self) -> list[str]:
        """Returns a list of all available filter metric keys."""
    def get_metric_description(self, metric_name: str) -> str:
        """Returns a user-friendly description for a given metric."""
    def _create_event_handlers(self):
        """Sets up all global event listeners and state management."""
    def _run_task_with_progress(self, task_func: Callable, output_components: list, progress: Callable, *args) -> Generator[dict, None, None]:
        """Executes a background task while streaming progress updates to the UI."""
    def _toggle_pause(self, tracker: 'AdvancedProgressTracker') -> str:
        """Toggles the pause state of the current running task."""
    def run_system_diagnostics(self) -> Generator[str, None, None]:
        """Runs a comprehensive suite of system checks and a dry run."""
    def _create_pre_analysis_event(self, state: ApplicationState, *args: Any) -> 'PreAnalysisEvent':
        """Helper to construct a PreAnalysisEvent from UI arguments."""
    def _run_pipeline(self, pipeline_func: Callable, event: Any, progress: Callable, success_callback: Optional[Callable]=None, *args):
        """Generic wrapper to run a pipeline function and handle progress/errors."""
    def run_extraction_wrapper(self, current_state: ApplicationState, *args, progress=None):
        """Wrapper to execute the extraction pipeline."""
    def add_to_queue_handler(self, *args):
        """Adds a job to the batch processing queue."""
    def clear_queue_handler(self):
        """Clears all items from the batch queue."""
    def _batch_processor(self, item: BatchItem, progress_callback: Callable):
        """Callback to process a single item in the batch queue."""
    def start_batch_wrapper(self, workers: float):
        """Starts processing the batch queue with specified number of workers."""
    def stop_batch_handler(self):
        """Stops the batch processing."""
    def _save_session_log(self, output_dir_str: str):
        """Helper to save logs to the result directory."""
    def _on_extraction_success(self, result: dict, current_state: ApplicationState) -> dict:
        """Callback for successful extraction."""
    def _on_pre_analysis_success(self, result: dict, current_state: ApplicationState) -> dict:
        """Callback for successful pre-analysis."""
    def run_pre_analysis_wrapper(self, current_state: ApplicationState, *args, progress=None):
        """Wrapper to execute the pre-analysis pipeline."""
    def run_propagation_wrapper(self, scenes, current_state: ApplicationState, *args, progress=None):
        """Wrapper to execute the mask propagation pipeline."""
    def _on_propagation_success(self, result: dict, current_state: ApplicationState) -> dict:
        """Callback for successful propagation."""
    def run_analysis_wrapper(self, scenes, current_state: ApplicationState, *args, progress=None):
        """Wrapper to execute the full analysis pipeline."""
    def _on_analysis_success(self, result: dict, current_state: ApplicationState) -> dict:
        """Callback for successful analysis."""
    def run_session_load_wrapper(self, session_path: str, current_state: ApplicationState):
        """Loads a previous session and updates the UI state."""
    def _fix_strategy_visibility(self, strategy: str) -> dict:
        """Adjusts UI component visibility based on the selected seed strategy."""
    def _setup_visibility_toggles(self):
        """Configures dynamic visibility logic for UI components."""
    def get_inputs(self, keys: list[str]) -> list[gr.components.Component]:
        """Retrieves a list of UI components based on their registry keys."""
    def _setup_pipeline_handlers(self):
        """Configures event handlers for starting main processing pipelines."""
    @safe_ui_callback('Face Clustering')
    def on_identity_confidence_change(self, confidence: float, state: ApplicationState) -> gr.update:
        """Updates the face discovery gallery based on clustering confidence."""
    @safe_ui_callback('Face Selection')
    def on_discovered_face_select(self, state: ApplicationState, confidence: float, evt: gr.SelectData=None) -> tuple[str, Optional[np.ndarray], str]:
        """Handles selection of a face cluster from the discovery gallery."""
    @safe_ui_callback('Face Discovery')
    def on_find_people_from_video(self, current_state: ApplicationState, *args) -> tuple[str, gr.update, gr.update, float, ApplicationState]:
        """Scans the video for faces to populate the discovery gallery."""
    def _get_smart_mode_updates(self, is_enabled: bool) -> list[gr.update]:
        """Calculates slider updates when toggling 'Smart Mode'."""
    def _setup_filtering_handlers(self):
        """Configures event handlers for the filtering and export tab."""
    def on_preset_changed(self, preset_name: str) -> list[Any]:
        """Updates filter sliders when a preset is selected."""
    @safe_ui_callback('Filter Change')
    def on_filters_changed_wrapper(self, state: ApplicationState, gallery_view: str, show_overlay: bool, overlay_alpha: float, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> tuple[str, gr.update]:
        """Updates the results gallery when filters change."""
    @safe_ui_callback('Visual Diff')
    def calculate_visual_diff(self, gallery: gr.Gallery, state: ApplicationState, dedup_method_ui: str, dedup_thresh: int, ssim_thresh: float, lpips_thresh: float) -> Optional[np.ndarray]:
        """Computes a side-by-side comparison image for duplicate inspection."""
    @safe_ui_callback('Reset Filters')
    def on_reset_filters(self, state: ApplicationState) -> tuple:
        """Resets all filter settings to their defaults."""
    def on_auto_set_thresholds(self, per_metric_values: dict, p: int, *checkbox_values: bool) -> list[gr.update]:
        """Automatically sets filter thresholds based on data percentiles."""
    @safe_ui_callback('Export')
    def export_kept_frames_wrapper(self, state: ApplicationState, enable_crop: bool, crop_ars: str, crop_padding: int, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> str:
        """Wrapper to execute the final frame export."""
    @safe_ui_callback('Export Dry Run')
    def dry_run_export_wrapper(self, state: ApplicationState, enable_crop: bool, crop_ars: str, crop_padding: int, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> str:
        """Wrapper to perform a dry run of the export."""
    def on_auto_set_thresholds(self, per_metric_values: dict, p: int, *checkbox_values: bool) -> list[gr.update]:
        """Automatically sets filter thresholds based on data percentiles."""
    def export_kept_frames_wrapper(self, all_frames_data: list, output_dir: str, video_path: str, enable_crop: bool, crop_ars: str, crop_padding: int, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> str:
        """Wrapper to execute the final frame export."""
    def dry_run_export_wrapper(self, all_frames_data: list, output_dir: str, video_path: str, enable_crop: bool, crop_ars: str, crop_padding: int, require_face_match: bool, dedup_thresh: int, dedup_method_ui: str, *slider_values: float) -> str:
        """Wrapper to perform a dry run of the export."""
```

### `ðŸ“„ ui/gallery_utils.py`

```python
__all__ = ['build_scene_gallery_items', 'render_mask_overlay', 'on_filters_ch...
def _update_gallery(all_frames_data: list[dict], filters: dict, output_dir: str, gallery_view: str, show_overlay: bool, overlay_alpha: float, thumbnail_manager: Any, config: Any, logger: Any) -> tuple[str, gr.update]:
    """Updates the Gradio gallery based on applied filters."""
def on_filters_changed(event: FilterEvent, thumbnail_manager: Any, config: Any, logger: Any) -> dict:
    """Event handler for when filter settings are modified."""
def auto_set_thresholds(per_metric_values: dict, p: int, slider_keys: list[str], selected_metrics: list[str]) -> dict:
    """Calculates threshold values based on data percentiles."""
```

### `ðŸ“„ ui/handlers/__init__.py`

```python
"""UI Handlers package for Frame Extractor."""
__all__ = ['SceneHandler']
```

### `ðŸ“„ ui/handlers/scene_handler.py`

```python
class SceneHandler:
    """Handles scene-related UI operations (selection, filtering, undo, etc.)."""
    def __init__(self, app: 'AppUI'): ...
    def setup_handlers(self):
        """Configures event handlers for the scene selection tab (pagination, bulk actio..."""
    def _push_history(self, scenes: List[Dict], history: Deque) -> Deque:
        """Pushes the current scene state to the history stack for undo support."""
    def _undo_last_action(self, scenes: List[Dict], history: Deque, output_dir: str, view: str) -> tuple:
        """Reverts the last action by popping from the history stack."""
    def on_reset_scene_wrapper(self, scenes, shot_id, outdir, view, history, *ana_args):
        """Resets a scene's manual overrides to its initial state."""
    def on_select_for_edit(self, scenes, view, indexmap, outputdir, event: Optional[gr.EventData]=None):
        """Handles selection of a scene from the gallery for editing."""
    def on_editor_toggle(self, scenes, selected_shotid, outputfolder, view, new_status, history):
        """Toggles the included/excluded status of a scene."""
    def on_apply_bulk_scene_filters_extended(self, scenes, min_mask_pct, min_face_sim, min_quality, enable_face_filter, output_dir, view, history):
        """Applies bulk filters to scenes based on metric thresholds."""
```

### `ðŸ“„ ui/tabs/__init__.py`

```python
__all__ = ['ExtractionTabBuilder', 'SubjectTabBuilder', 'SceneTabBuilder', 'M...
```

### `ðŸ“„ ui/tabs/extraction_tab.py`

```python
class ExtractionTabBuilder:
    def __init__(self, app: 'AppUI'): ...
    def build(self):
        """Creates the content for the 'Source' tab."""
```

### `ðŸ“„ ui/tabs/filtering_tab.py`

```python
class FilteringTabBuilder:
    def __init__(self, app: 'AppUI'): ...
    def build(self):
        """Creates the content for the 'Export' tab."""
```

### `ðŸ“„ ui/tabs/metrics_tab.py`

```python
class MetricsTabBuilder:
    def __init__(self, app: 'AppUI'): ...
    def build(self):
        """Creates the content for the 'Metrics' tab."""
```

### `ðŸ“„ ui/tabs/scene_tab.py`

```python
class SceneTabBuilder:
    def __init__(self, app: 'AppUI'): ...
    def build(self):
        """Creates the content for the 'Scenes' tab."""
```

### `ðŸ“„ ui/tabs/subject_tab.py`

```python
class SubjectTabBuilder:
    def __init__(self, app: 'AppUI'): ...
    def build(self):
        """Creates the content for the 'Subject' tab."""
```
