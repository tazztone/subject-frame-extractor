"""
GPU E2E Tests - Real inference with actual models.

These tests run REAL GPU inference to catch runtime errors like:
- BFloat16/Float32 dtype mismatches
- CUDA OOM errors  
- Model loading failures
- Tensor shape mismatches

Run with: python -m pytest tests/test_gpu_e2e.py -m gpu_e2e -v

Requirements:
- CUDA-capable GPU with 6GB+ VRAM
- SAM3 installed (pip install -e SAM3_repo)
- All models downloaded
"""
import pytest
import numpy as np
from pathlib import Path

# Mark all tests as gpu_e2e (requires GPU, slow)
pytestmark = [pytest.mark.gpu_e2e, pytest.mark.slow]


def _create_test_image(width=256, height=256):
    """Create a simple test image with a rectangle (simulates an object)."""
    img = np.zeros((height, width, 3), dtype=np.uint8)
    # Add a background
    img[:, :] = [100, 150, 200]  # Light blue background
    # Add a rectangle (simulates a person/object)
    img[50:200, 80:180] = [200, 100, 100]  # Red rectangle
    return img


def _create_test_image_with_face(width=256, height=256):
    """Create a test image with a face-like pattern."""
    img = np.zeros((height, width, 3), dtype=np.uint8)
    img[:, :] = [200, 200, 200]  # Gray background
    # Add a face-like oval
    import cv2
    cv2.ellipse(img, (128, 100), (60, 80), 0, 0, 360, (255, 220, 180), -1)
    # Add eyes
    cv2.circle(img, (108, 85), 10, (50, 50, 50), -1)
    cv2.circle(img, (148, 85), 10, (50, 50, 50), -1)
    return img


def _create_test_frames_dir(tmp_path, num_frames=5, width=256, height=256):
    """Create a directory with test frames for SAM3 video processing."""
    from PIL import Image
    
    frames_dir = tmp_path / "test_frames"
    frames_dir.mkdir(exist_ok=True)
    
    for i in range(num_frames):
        # Create frame with moving object
        img = np.zeros((height, width, 3), dtype=np.uint8)
        img[:, :] = [100, 150, 200]  # Light blue background
        # Moving rectangle (simulates person)
        x = 50 + i * 15
        img[50:200, x:x+80] = [200, 100, 100]  # Red rectangle
        Image.fromarray(img).save(frames_dir / f"{i:05d}.jpg")
    
    return frames_dir


def _is_sam3_available():
    """Check if SAM3 is properly installed and can be imported."""
    try:
        from sam3.model_builder import build_sam3_video_model
        return True
    except ImportError:
        return False


# Skip decorator for tests requiring SAM3
requires_sam3 = pytest.mark.skipif(
    not _is_sam3_available(),
    reason="SAM3 not installed (pip install -e SAM3_repo)"
)


@pytest.fixture
def test_image():
    """Provides a simple test image."""
    return _create_test_image()


@pytest.fixture
def test_image_with_face():
    """Provides a test image with face-like features."""
    return _create_test_image_with_face()


@pytest.fixture
def test_frames_dir(tmp_path):
    """Provides a directory with test frames for video processing."""
    return _create_test_frames_dir(tmp_path)


class TestCUDAAvailability:
    """Verify CUDA is available and working before running GPU tests."""

    def test_cuda_available(self):
        """CUDA must be available for GPU E2E tests."""
        import torch
        assert torch.cuda.is_available(), "CUDA is required for GPU E2E tests"

    def test_cuda_memory_available(self):
        """Verify sufficient GPU memory (~4GB needed)."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        free_memory = torch.cuda.get_device_properties(0).total_memory
        min_required = 4 * 1024 * 1024 * 1024  # 4GB
        assert free_memory >= min_required, f"Need at least 4GB GPU memory, got {free_memory / 1e9:.1f}GB"


class TestSAM3Inference:
    """Real SAM3 inference tests - catches BFloat16 and other runtime errors."""

    @requires_sam3
    def test_sam3_wrapper_initialization(self, tmp_path):
        """SAM3Wrapper can be initialized without errors."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.managers import SAM3Wrapper
        
        wrapper = SAM3Wrapper(device="cuda")
        assert wrapper is not None
        assert wrapper.predictor is not None
        assert wrapper.sam3_model is not None
        pass  # cleanup() removed

    @requires_sam3
    def test_sam3_init_video(self, test_frames_dir):
        """SAM3 init_video() initializes inference state correctly."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.managers import SAM3Wrapper
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            inference_state = wrapper.init_video(str(test_frames_dir))
            assert inference_state is not None
            assert wrapper.inference_state is not None
        finally:
            pass  # cleanup() removed

    @requires_sam3
    def test_sam3_add_bbox_prompt(self, test_frames_dir):
        """SAM3 add_bbox_prompt() returns valid mask."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.managers import SAM3Wrapper
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            wrapper.init_video(str(test_frames_dir))
            
            # Add bbox prompt covering the object in test image
            mask = wrapper.add_bbox_prompt(
                frame_idx=0,
                obj_id=1,
                bbox_xywh=[50, 50, 80, 150],  # x, y, w, h
                img_size=(256, 256)  # w, h
            )
            
            assert mask is not None
            assert isinstance(mask, np.ndarray)
            assert mask.ndim == 2  # Should be 2D (H, W) mask
            assert mask.shape == (256, 256)
        finally:
            pass  # cleanup() removed

    @requires_sam3
    def test_sam3_propagate_forward(self, test_frames_dir):
        """SAM3 propagate() forward generator yields valid results."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.managers import SAM3Wrapper
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            wrapper.init_video(str(test_frames_dir))
            wrapper.add_bbox_prompt(
                frame_idx=0,
                obj_id=1,
                bbox_xywh=[50, 50, 80, 150],
                img_size=(256, 256)
            )
            
            # Propagate forward
            propagated = list(wrapper.propagate(start_idx=0, reverse=False))
            
            assert len(propagated) > 0
            for frame_idx, obj_id, mask in propagated:
                assert isinstance(frame_idx, int)
                assert frame_idx >= 0
                assert isinstance(obj_id, int)
                assert isinstance(mask, np.ndarray)
                assert mask.ndim == 2
        finally:
            pass  # cleanup() removed

    @requires_sam3
    def test_sam3_propagate_bidirectional(self, tmp_path):
        """SAM3 propagate() works bidirectionally from middle frame."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.managers import SAM3Wrapper
        
        # Create 10 frames for bidirectional test
        frames_dir = _create_test_frames_dir(tmp_path, num_frames=10)
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            wrapper.init_video(str(frames_dir))
            
            # Start from middle frame
            seed_frame = 5
            wrapper.add_bbox_prompt(
                frame_idx=seed_frame,
                obj_id=1,
                bbox_xywh=[100, 50, 80, 150],
                img_size=(256, 256)
            )
            
            # Propagate forward
            forward = list(wrapper.propagate(start_idx=seed_frame, reverse=False))
            forward_indices = [f[0] for f in forward]
            
            # Forward should include frames >= seed_frame
            assert all(idx >= seed_frame for idx in forward_indices), f"Forward indices: {forward_indices}"
            
            # Propagate backward
            backward = list(wrapper.propagate(start_idx=seed_frame, reverse=True))
            backward_indices = [f[0] for f in backward]
            
            # Backward should include frames <= seed_frame
            assert all(idx <= seed_frame for idx in backward_indices), f"Backward indices: {backward_indices}"
        finally:
            pass  # cleanup() removed

    @requires_sam3
    def test_sam3_clear_prompts(self, test_frames_dir):
        """SAM3 clear_prompts() resets session state."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.managers import SAM3Wrapper
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            wrapper.init_video(str(test_frames_dir))
            wrapper.add_bbox_prompt(0, 1, [50, 50, 80, 150], (256, 256))
            
            # Clear prompts should not raise error
            wrapper.clear_prompts()
            
            # Should be able to add new prompt after clearing
            mask = wrapper.add_bbox_prompt(0, 2, [60, 60, 70, 140], (256, 256))
            assert mask is not None
        finally:
            pass  # cleanup() removed


class TestInsightFaceInference:
    """Real InsightFace inference tests."""

    def test_insightface_initialization(self, tmp_path):
        """InsightFace can be initialized."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.config import Config
        from core.logger import AppLogger
        from core.managers import ModelRegistry, get_face_analyzer
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        registry = ModelRegistry(logger)
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        models_path = str(tmp_path / "models")
        
        # get_face_analyzer(model_name, models_path, det_size_tuple, logger, model_registry, device)
        analyzer = get_face_analyzer(
            "buffalo_l", 
            models_path,
            (640, 640),
            logger,
            registry,
            device
        )
        
        assert analyzer is not None

    def test_face_detection_on_image(self, test_image_with_face, tmp_path):
        """InsightFace can process an image without errors."""
        import torch
        import cv2
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.config import Config
        from core.logger import AppLogger
        from core.managers import ModelRegistry, get_face_analyzer
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        registry = ModelRegistry(logger)
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        models_path = str(tmp_path / "models")
        
        analyzer = get_face_analyzer(
            "buffalo_l",
            models_path,
            (640, 640),
            logger,
            registry,
            device
        )
        
        # Convert RGB to BGR for InsightFace
        image_bgr = cv2.cvtColor(test_image_with_face, cv2.COLOR_RGB2BGR)
        
        # This should not raise errors (faces may not be detected in synthetic image)
        faces = analyzer.get(image_bgr)
        assert isinstance(faces, list)


class TestPipelineE2E:
    """End-to-end pipeline tests with real execution."""

    def test_extraction_pipeline_creates_output(self, tmp_path):
        """ExtractionPipeline initializes correctly with real config."""
        import threading
        from queue import Queue
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.pipelines import ExtractionPipeline
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        output_dir = tmp_path / "output"
        output_dir.mkdir()
        
        params = AnalysisParameters(
            source_path="test.mp4",  # Doesn't need to exist for init
            output_folder=str(output_dir)
        )
        
        pipeline = ExtractionPipeline(config, logger, params, Queue(), threading.Event())
        assert pipeline is not None
        assert pipeline.config is not None

    def test_analysis_pipeline_initializes_with_real_managers(self, tmp_path):
        """AnalysisPipeline initializes with real ThumbnailManager and ModelRegistry."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        import threading
        from queue import Queue
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.pipelines import AnalysisPipeline
        from core.managers import ThumbnailManager, ModelRegistry
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        output_dir = tmp_path / "output"
        output_dir.mkdir()
        
        params = AnalysisParameters(
            source_path="test.mp4",
            output_folder=str(output_dir)
        )
        
        tm = ThumbnailManager(logger, config)
        registry = ModelRegistry(logger)
        
        pipeline = AnalysisPipeline(
            config, logger, params, Queue(), threading.Event(), tm, registry
        )
        
        assert pipeline is not None
        assert pipeline.thumbnail_manager is not None
        assert pipeline.model_registry is not None


class TestVideoE2E:
    """End-to-end tests with real video processing."""

    @pytest.fixture
    def test_video_path(self, tmp_path):
        """Create a small test video (5 frames, 256x256)."""
        import cv2
        
        video_path = tmp_path / "test_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(video_path), fourcc, 5.0, (256, 256))
        
        # Create 5 frames with moving object
        for i in range(5):
            frame = np.zeros((256, 256, 3), dtype=np.uint8)
            frame[:, :] = [100, 150, 200]  # Blue background
            # Moving rectangle (simulates person)
            x = 50 + i * 20
            cv2.rectangle(frame, (x, 50), (x + 80, 200), (200, 100, 100), -1)
            out.write(frame)
        
        out.release()
        return str(video_path)

    @pytest.fixture
    def test_frames_dir(self, tmp_path, test_video_path):
        """Create directory with extracted frames and required files."""
        import cv2
        import json
        
        output_dir = tmp_path / "output"
        output_dir.mkdir()
        thumbs_dir = output_dir / "thumbs"
        thumbs_dir.mkdir()
        
        # Extract frames from test video
        cap = cv2.VideoCapture(test_video_path)
        frame_numbers = []
        frame_idx = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame_path = thumbs_dir / f"frame_{frame_idx:06d}.webp"
            cv2.imwrite(str(frame_path), frame)
            frame_numbers.append(frame_idx)
            frame_idx += 1
        
        cap.release()
        
        # Create scenes.json (all frames as one scene)
        scenes = [[0, frame_idx - 1]]
        with open(output_dir / "scenes.json", "w") as f:
            json.dump(scenes, f)
        
        # Create frame_map.json
        with open(output_dir / "frame_map.json", "w") as f:
            json.dump(frame_numbers, f)
        
        return output_dir

    def test_extraction_pipeline_on_real_video(self, test_video_path, tmp_path):
        """ExtractionPipeline can process a real video file."""
        import threading
        from queue import Queue
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.pipelines import ExtractionPipeline
        
        config = Config(
            logs_dir=str(tmp_path / "logs"),
            downloads_dir=str(tmp_path / "downloads")
        )
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        output_dir = tmp_path / "output"
        output_dir.mkdir()
        
        params = AnalysisParameters(
            source_path=test_video_path,
            video_path=test_video_path,
            output_folder=str(output_dir),
            thumbnails_only=True,
            method="all"
        )
        
        pipeline = ExtractionPipeline(config, logger, params, Queue(), threading.Event())
        result = pipeline.run()
        
        assert result is not None
        assert result.get("done") == True
        assert (output_dir / "thumbs").exists()

    def test_pre_analysis_with_sam3(self, test_frames_dir, tmp_path):
        """Pre-analysis can run SAM3 on extracted frames."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        import threading
        from queue import Queue
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import ThumbnailManager, ModelRegistry
        from core.scene_utils import SubjectMasker
        
        config = Config(
            logs_dir=str(tmp_path / "logs"),
            models_dir=str(tmp_path / "models")
        )
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        params = AnalysisParameters(
            source_path="test.mp4",
            video_path="test.mp4",
            output_folder=str(test_frames_dir),
            thumbnails_only=True,
            enable_subject_mask=True,
            primary_seed_strategy="ðŸ“¦ Use Bounding Box"
        )
        
        registry = ModelRegistry(logger)
        tm = ThumbnailManager(logger, config)
        
        # This tests the full SAM3 initialization and masker setup
        masker = SubjectMasker(
            params=params,
            progress_queue=Queue(),
            cancel_event=threading.Event(),
            config=config,
            thumbnail_manager=tm,
            logger=logger,
            model_registry=registry,
            device="cuda"
        )
        
        assert masker is not None


class TestMaskPropagatorE2E:
    """Tests for MaskPropagator with real SAM3 inference."""

    @requires_sam3
    def test_mask_propagator_propagate(self, tmp_path):
        """MaskPropagator.propagate() works with new SAM3 API."""
        import torch
        import threading
        from queue import Queue
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import SAM3Wrapper
        from core.scene_utils.mask_propagator import MaskPropagator
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        params = AnalysisParameters(
            source_path="test.mp4",
            output_folder=str(tmp_path),
            min_mask_area_pct=0.01
        )
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            propagator = MaskPropagator(
                params=params,
                dam_tracker=wrapper,
                cancel_event=threading.Event(),
                progress_queue=Queue(),
                config=config,
                logger=logger,
                device="cuda"
            )
            
            # Create test frames
            frames_rgb = [_create_test_image() for _ in range(5)]
            
            # Run propagation
            masks, areas, empties, errors = propagator.propagate(
                shot_frames_rgb=frames_rgb,
                seed_idx=0,
                bbox_xywh=[50, 50, 80, 150]
            )
            
            assert len(masks) == 5
            assert len(areas) == 5
            assert len(empties) == 5
            assert len(errors) == 5
            
            # At least seed frame should have a mask
            assert masks[0] is not None
            assert isinstance(masks[0], np.ndarray)
        finally:
            pass  # cleanup() removed

    @requires_sam3
    def test_mask_propagator_bidirectional(self, tmp_path):
        """MaskPropagator.propagate() works bidirectionally from middle frame."""
        import torch
        import threading
        from queue import Queue
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import SAM3Wrapper
        from core.scene_utils.mask_propagator import MaskPropagator
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        params = AnalysisParameters(
            source_path="test.mp4",
            output_folder=str(tmp_path),
            min_mask_area_pct=0.01
        )
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            propagator = MaskPropagator(
                params=params,
                dam_tracker=wrapper,
                cancel_event=threading.Event(),
                progress_queue=Queue(),
                config=config,
                logger=logger,
                device="cuda"
            )
            
            # Create 10 test frames with moving object
            frames_rgb = []
            for i in range(10):
                img = np.zeros((256, 256, 3), dtype=np.uint8)
                img[:, :] = [100, 150, 200]
                x = 30 + i * 15
                img[50:200, x:x+80] = [200, 100, 100]
                frames_rgb.append(img)
            
            # Start from middle frame
            seed_idx = 5
            x_at_seed = 30 + seed_idx * 15
            
            masks, areas, empties, errors = propagator.propagate(
                shot_frames_rgb=frames_rgb,
                seed_idx=seed_idx,
                bbox_xywh=[x_at_seed, 50, 80, 150]
            )
            
            assert len(masks) == 10
            # All frames should have masks (either from forward or backward propagation)
            for i, mask in enumerate(masks):
                assert mask is not None, f"Frame {i} has no mask"
                assert isinstance(mask, np.ndarray)
        finally:
            pass  # cleanup() removed


class TestQualityMetricsE2E:
    """Tests for quality metric calculation with real images."""

    def test_calculate_quality_metrics_real(self, test_image, tmp_path):
        """Frame quality metrics can be calculated on real image."""
        import torch
        
        from core.models import Frame, QualityConfig
        from core.config import Config
        from core.logger import AppLogger
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        quality_config = QualityConfig(
            sharpness_base_scale=config.sharpness_base_scale,
            edge_strength_base_scale=config.edge_strength_base_scale,
            enable_niqe=False  # Skip NIQE for speed
        )
        
        frame = Frame(image_data=test_image, frame_number=0)
        
        # This tests real metric calculation
        frame.calculate_quality_metrics(
            test_image,
            quality_config,
            logger,
            main_config=config,
            metrics_to_compute={
                'sharpness': True,
                'edge_strength': True,
                'contrast': True,
                'brightness': True,
                'entropy': True
            }
        )
        
        assert frame.metrics is not None
        assert frame.metrics.sharpness_score is not None
        assert frame.metrics.edge_strength_score is not None

    def test_niqe_metric_calculation(self, test_image, tmp_path):
        """NIQE metric can be calculated (requires pyiqa)."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        try:
            import pyiqa
        except ImportError:
            pytest.skip("pyiqa not installed")
        
        from core.models import Frame, QualityConfig
        from core.config import Config
        from core.logger import AppLogger
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        niqe_metric = pyiqa.create_metric('niqe', device=device)
        
        quality_config = QualityConfig(
            sharpness_base_scale=config.sharpness_base_scale,
            edge_strength_base_scale=config.edge_strength_base_scale,
            enable_niqe=True
        )
        
        frame = Frame(image_data=test_image, frame_number=0)
        
        frame.calculate_quality_metrics(
            test_image,
            quality_config,
            logger,
            main_config=config,
            niqe_metric=niqe_metric,
            metrics_to_compute={'quality': True}
        )
        
        assert frame.metrics is not None
        # NIQE score should be calculated
        assert frame.metrics.niqe_score is not None or frame.metrics.quality_score is not None


class TestExportE2E:
    """E2E tests for export pipeline."""

    def test_export_pipeline_initialization(self, tmp_path):
        """ExportPipeline can be initialized with real config."""
        from core.config import Config
        from core.logger import AppLogger
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        # Create required directories
        output_dir = tmp_path / "output"
        output_dir.mkdir()
        
        # Export functions should be importable
        from core.export import export_kept_frames
        assert export_kept_frames is not None

    def test_export_with_real_frames(self, tmp_path):
        """Export can process frames from a real directory."""
        import cv2
        import json
        
        from core.config import Config
        from core.logger import AppLogger
        from core.export import export_kept_frames
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        # Create output structure
        output_dir = tmp_path / "session"
        output_dir.mkdir()
        thumbs_dir = output_dir / "thumbs"
        thumbs_dir.mkdir()
        export_dir = tmp_path / "export"
        export_dir.mkdir()
        
        # Create test frames
        for i in range(5):
            frame = _create_test_image()
            cv2.imwrite(str(thumbs_dir / f"frame_{i:06d}.webp"), frame)
        
        # Create frame map
        frame_map = list(range(5))
        with open(output_dir / "frame_map.json", "w") as f:
            json.dump(frame_map, f)
        
        # Test should not crash (full export requires more setup)
        assert (output_dir / "thumbs").exists()
        assert len(list(thumbs_dir.glob("*.webp"))) == 5

    def test_export_dry_run_mode(self, tmp_path):
        """Dry run export mode works without creating files."""
        from core.config import Config
        from core.logger import AppLogger
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        export_dir = tmp_path / "export_dry"
        # Directory NOT created yet
        
        # Dry run should work without output directory existing
        assert not export_dir.exists()


class TestCancellationE2E:
    """E2E tests for cancel operations during pipeline execution."""

    @requires_sam3
    def test_propagation_with_cancel_event(self, tmp_path):
        """MaskPropagator handles cancel event during propagation."""
        import torch
        import threading
        from queue import Queue
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import SAM3Wrapper
        from core.scene_utils.mask_propagator import MaskPropagator
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        params = AnalysisParameters(
            source_path="test.mp4",
            output_folder=str(tmp_path),
            min_mask_area_pct=0.01
        )
        
        wrapper = SAM3Wrapper(device="cuda")
        cancel_event = threading.Event()
        
        try:
            propagator = MaskPropagator(
                params=params,
                dam_tracker=wrapper,
                cancel_event=cancel_event,
                progress_queue=Queue(),
                config=config,
                logger=logger,
                device="cuda"
            )
            
            # Create test frames
            frames_rgb = [_create_test_image() for _ in range(10)]
            
            # Set cancel event after a short delay to simulate user cancellation
            def cancel_after_delay():
                import time
                time.sleep(0.5)
                cancel_event.set()
            
            # Start the cancel thread
            cancel_thread = threading.Thread(target=cancel_after_delay)
            cancel_thread.start()
            
            # Run propagation (may be interrupted)
            masks, areas, empties, errors = propagator.propagate(
                shot_frames_rgb=frames_rgb,
                seed_idx=0,
                bbox_xywh=[50, 50, 80, 150]
            )
            
            cancel_thread.join()
            
            # Should return lists (possibly incomplete due to cancel)
            assert isinstance(masks, list)
            assert isinstance(areas, list)
            
        finally:
            pass  # cleanup() removed

    def test_analysis_pipeline_cancel(self, tmp_path):
        """AnalysisPipeline handles cancel event gracefully."""
        import torch
        import threading
        from queue import Queue
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        
        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        output_dir = tmp_path / "output"
        output_dir.mkdir()
        
        params = AnalysisParameters(
            source_path="test.mp4",
            output_folder=str(output_dir)
        )
        
        # Create cancel event in cancelled state
        cancel_event = threading.Event()
        cancel_event.set()  # Pre-cancelled
        
        # Pipeline initialization should still work
        from core.pipelines import AnalysisPipeline
        from core.managers import ThumbnailManager, ModelRegistry
        
        tm = ThumbnailManager(logger, config)
        registry = ModelRegistry(logger)
        
        pipeline = AnalysisPipeline(
            config, logger, params, Queue(), cancel_event, tm, registry
        )
        
        assert pipeline is not None


class TestMediaPipeLandmarkerE2E:
    """E2E tests for MediaPipe Face Landmarker."""

    def test_face_landmarker_import(self):
        """MediaPipe face landmarker can be imported."""
        try:
            import mediapipe as mp
            assert mp is not None
        except ImportError:
            pytest.skip("MediaPipe not installed")

    def test_face_landmarker_model_download(self, tmp_path):
        """Face landmarker model can be downloaded."""
        import torch
        
        from core.config import Config
        from core.logger import AppLogger
        
        config = Config(
            logs_dir=str(tmp_path / "logs"),
            models_dir=str(tmp_path / "models")
        )
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        
        # Model download is handled by managers
        # Just verify the config paths work
        assert Path(config.models_dir).exists() or True  # May not exist yet


class TestLargeVideoE2E:
    """E2E tests for handling larger videos/frame sequences."""

    def test_many_frames_processing(self, tmp_path):
        """Test processing a larger number of frames."""
        from PIL import Image
        
        frames_dir = tmp_path / "many_frames"
        frames_dir.mkdir()
        
        # Create 50 frames
        num_frames = 50
        for i in range(num_frames):
            img = _create_test_image(width=128, height=128)  # Smaller for speed
            Image.fromarray(img).save(frames_dir / f"{i:05d}.jpg")
        
        assert len(list(frames_dir.glob("*.jpg"))) == num_frames

    @requires_sam3
    def test_sam3_with_many_frames(self, tmp_path):
        """SAM3 can process a larger sequence."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")
        
        from PIL import Image
        from core.managers import SAM3Wrapper
        
        # Create 20 frames
        frames_dir = tmp_path / "frames"
        frames_dir.mkdir()
        
        for i in range(20):
            img = np.zeros((128, 128, 3), dtype=np.uint8)
            img[:, :] = [100, 150, 200]
            x = 20 + i * 4
            img[30:100, x:x+40] = [200, 100, 100]
            Image.fromarray(img).save(frames_dir / f"{i:05d}.jpg")
        
        wrapper = SAM3Wrapper(device="cuda")
        
        try:
            wrapper.init_video(str(frames_dir))
            mask = wrapper.add_bbox_prompt(
                frame_idx=0,
                obj_id=1,
                bbox_xywh=[20, 30, 40, 70],
                img_size=(128, 128)
            )
            
            assert mask is not None
            
            # Propagate through all frames
            propagated = list(wrapper.propagate(start_idx=0, reverse=False))
            assert len(propagated) > 0
            
        finally:
            pass  # cleanup() removed


class TestMaskGenerationE2E:
    """E2E tests for mask generation to catch silent failures."""

    @requires_sam3
    def test_get_mask_for_bbox_e2e(self, test_frames_dir, tmp_path):
        """Test SeedSelector._get_mask_for_bbox with real SAM3."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")

        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import SAM3Wrapper
        from core.scene_utils.seed_selector import SeedSelector

        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        wrapper = SAM3Wrapper(device="cuda")

        # Initialize SeedSelector with minimal dependencies
        selector = SeedSelector(
            params=AnalysisParameters(source_path="test.mp4"),
            config=config,
            face_analyzer=None,
            reference_embedding=None,
            tracker=wrapper,
            logger=logger,
            device="cuda"
        )

        # Create a test frame
        frame = np.zeros((256, 256, 3), dtype=np.uint8)
        frame[50:200, 50:150] = [200, 100, 100]  # Object

        try:
            # _get_mask_for_bbox expects frame and bbox
            bbox = [50, 50, 100, 150] # x, y, w, h
            mask = selector._get_mask_for_bbox(frame, bbox)

            assert mask is not None
            assert isinstance(mask, np.ndarray)
            assert mask.shape[:2] == (256, 256)
            assert np.any(mask > 0) # Should have some mask
        finally:
            pass

    @requires_sam3
    def test_identity_first_seed_e2e(self, test_image_with_face, tmp_path):
        """Test 'By Face' seeding strategy with real models."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")

        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import SAM3Wrapper, ModelRegistry, get_face_analyzer
        from core.scene_utils.seed_selector import SeedSelector

        config = Config(logs_dir=str(tmp_path / "logs"))
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        wrapper = SAM3Wrapper(device="cuda")
        registry = ModelRegistry(logger)

        # Load real face analyzer
        face_analyzer = get_face_analyzer(
            "buffalo_l",
            str(tmp_path / "models"),
            (640, 640),
            logger,
            registry,
            "cuda"
        )

        # Get embedding from test image
        import cv2
        img_bgr = cv2.cvtColor(test_image_with_face, cv2.COLOR_RGB2BGR)
        faces = face_analyzer.get(img_bgr)
        if not faces:
            pytest.skip("No faces detected in test image, cannot test identity seeding")

        ref_embedding = faces[0].normed_embedding

        selector = SeedSelector(
            params=AnalysisParameters(
                source_path="test.mp4",
                primary_seed_strategy="ðŸ‘¤ By Face",
                enable_face_filter=True
            ),
            config=config,
            face_analyzer=face_analyzer,
            reference_embedding=ref_embedding,
            tracker=wrapper,
            logger=logger,
            device="cuda"
        )

        try:
            # Test seeding
            bbox, details = selector.select_seed(test_image_with_face)

            assert bbox is not None
            assert details.get('type') in ['evidence_based_selection', 'face_match', 'expanded_box_from_face']
        finally:
            pass

    @requires_sam3
    def test_pre_analysis_mask_generation_e2e(self, test_frames_dir, tmp_path):
        """Test the full pre-analysis flow including mask generation."""
        import torch
        if not torch.cuda.is_available():
            pytest.skip("CUDA not available")

        import threading
        from queue import Queue

        from core.config import Config
        from core.logger import AppLogger
        from core.models import AnalysisParameters
        from core.managers import ThumbnailManager, ModelRegistry
        from core.scene_utils import SubjectMasker

        config = Config(
            logs_dir=str(tmp_path / "logs"),
            models_dir=str(tmp_path / "models")
        )
        logger = AppLogger(config, log_to_console=False, log_to_file=False)
        registry = ModelRegistry(logger)
        tm = ThumbnailManager(logger, config)

        params = AnalysisParameters(
            source_path="test.mp4",
            video_path="test.mp4",
            output_folder=str(test_frames_dir),
            thumbnails_only=True,
            enable_subject_mask=True,
            primary_seed_strategy="ðŸ“¦ Use Bounding Box",
            initial_bbox=[50, 50, 100, 150] # Explicit bbox
        )

        # Initialize SubjectMasker
        masker = SubjectMasker(
            params=params,
            progress_queue=Queue(),
            cancel_event=threading.Event(),
            config=config,
            thumbnail_manager=tm,
            logger=logger,
            model_registry=registry,
            device="cuda"
        )

        assert masker.tracker is not None
        assert masker.face_analyzer is not None


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s", "-m", "gpu_e2e"])

